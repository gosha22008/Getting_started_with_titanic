{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 603,
      "metadata": {
        "id": "rI2YnWUYAG4g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sbn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 604,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Yvi9muAQMP",
        "outputId": "eaeb7c5f-a383-437b-947c-148988b71fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ],
      "source": [
        "data_train = pd.read_csv('train(1).csv')\n",
        "data_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 605,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nS8jhzvAV89",
        "outputId": "dd83c954-478c-409e-8490-fa7819edd389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 605,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8Bq08mJlFWeb",
        "outputId": "90e59692-5f41-49ba-80e6-864f37281774"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
              "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
              "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
              "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
              "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
              "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
              "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
              "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
              "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
              "\n",
              "            Parch        Fare  \n",
              "count  891.000000  891.000000  \n",
              "mean     0.381594   32.204208  \n",
              "std      0.806057   49.693429  \n",
              "min      0.000000    0.000000  \n",
              "25%      0.000000    7.910400  \n",
              "50%      0.000000   14.454200  \n",
              "75%      0.000000   31.000000  \n",
              "max      6.000000  512.329200  "
            ]
          },
          "execution_count": 606,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 607,
      "metadata": {
        "id": "ODCfVQGWAxwt"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "_neiAp5oGGgi",
        "outputId": "7e69710d-cf80-4f16-c404-98aeb83deff2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Age', ylabel='Count'>"
            ]
          },
          "execution_count": 608,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sbn.histplot(data_train['Age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "0SWpR3bQGPjQ",
        "outputId": "384e5b0f-2822-4a70-c624-a5833227d1b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gosha\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Age'>"
            ]
          },
          "execution_count": 609,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sbn.boxplot(data_train['Age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxuQDj2JGXfm",
        "outputId": "0a0daf1e-8473-4d6d-dff7-7b9213808f54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    714.000000\n",
              "mean      29.699118\n",
              "std       14.526497\n",
              "min        0.420000\n",
              "25%       20.125000\n",
              "50%       28.000000\n",
              "75%       38.000000\n",
              "max       80.000000\n",
              "Name: Age, dtype: float64"
            ]
          },
          "execution_count": 610,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['Age'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLSoDFpCGmsi",
        "outputId": "a4441746-9d21-47b5-ec6c-fe02ae3057dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "медианный возраст по полу: \n",
            " Sex\n",
            "female    27.0\n",
            "male      29.0\n",
            "Name: Age, dtype: float64 \n",
            "\n",
            "средний возраст по полу: \n",
            " Sex\n",
            "female    27.915709\n",
            "male      30.726645\n",
            "Name: Age, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('медианный возраст по полу: \\n', data_train.groupby('Sex')['Age'].median(), '\\n')\n",
        "print('средний возраст по полу: \\n', data_train.groupby('Sex')['Age'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QJGlKlwGvfm",
        "outputId": "53aa719f-1e2b-426b-ce51-757bf5e52234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "средний возраст по полу и классу: \n",
            " Pclass  Sex   \n",
            "1       female    34.611765\n",
            "        male      41.281386\n",
            "2       female    28.722973\n",
            "        male      30.740707\n",
            "3       female    21.750000\n",
            "        male      26.507589\n",
            "Name: Age, dtype: float64 \n",
            "\n",
            "мединный возраст по полу и классу: \n",
            " Pclass  Sex   \n",
            "1       female    35.0\n",
            "        male      40.0\n",
            "2       female    28.0\n",
            "        male      30.0\n",
            "3       female    21.5\n",
            "        male      25.0\n",
            "Name: Age, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('средний возраст по полу и классу: \\n', data_train.groupby(['Pclass', 'Sex'])['Age'].mean(), '\\n')\n",
        "\n",
        "print('мединный возраст по полу и классу: \\n', data_train.groupby(['Pclass', 'Sex'])['Age'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3bu4b9mNwLH",
        "outputId": "14613e71-a794-48c2-9987-bfc5ebe81c9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pclass  Sex   \n",
              "1       female    35.0\n",
              "        male      40.0\n",
              "2       female    28.0\n",
              "        male      30.0\n",
              "3       female    21.5\n",
              "        male      25.0\n",
              "Name: Age, dtype: float64"
            ]
          },
          "execution_count": 613,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.groupby(['Pclass', 'Sex'])['Age'].median()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V0G6l7URfZUs"
      },
      "source": [
        "Заполню пустые значания Age в соответствии с распределением возраста по полу и классу билета выше. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "metadata": {
        "id": "_ch63dL9S3jc"
      },
      "outputs": [],
      "source": [
        "def set_age(data_train):\n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 1) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[1, 'female']\n",
        "                        \n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 1) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[1, 'male']\n",
        "\n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 2) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[2, 'female']\n",
        "\n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 2) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[2, 'male']\n",
        "\n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 3) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[3, 'female']\n",
        "\n",
        "    data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 3) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[3, 'male']\n",
        "\n",
        "    return data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 615,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "O9NF4ZNgS3jc",
        "outputId": "461d2ce2-7706-4ac1-e0ec-e4f8102355d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>21.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  21.5      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  \n",
              "0        0         A/5 21171   7.2500   NaN        S  \n",
              "1        0          PC 17599  71.2833   C85        C  \n",
              "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3        0            113803  53.1000  C123        S  \n",
              "4        0            373450   8.0500   NaN        S  \n",
              "..     ...               ...      ...   ...      ...  \n",
              "886      0            211536  13.0000   NaN        S  \n",
              "887      0            112053  30.0000   B42        S  \n",
              "888      2        W./C. 6607  23.4500   NaN        S  \n",
              "889      0            111369  30.0000  C148        C  \n",
              "890      0            370376   7.7500   NaN        Q  \n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "execution_count": 615,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_age(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "metadata": {
        "id": "MWApX12ETUdB"
      },
      "outputs": [],
      "source": [
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 1) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[1, 'female']\n",
        "                     \n",
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 1) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[1, 'male']\n",
        "\n",
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 2) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[2, 'female']\n",
        "\n",
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 2) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[2, 'male']\n",
        "\n",
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 3) & (data_train['Sex'] == 'female'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[3, 'female']\n",
        "\n",
        "# data_train.loc[(data_train['Age'].isnull()) & (data_train['Pclass'] == 3) & (data_train['Sex'] == 'male'), 'Age'] = data_train.groupby(['Pclass', 'Sex'])['Age'].median().loc[3, 'male']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWZs8UTjcRUd",
        "outputId": "b26d6fef-b493-4f18-dfc3-e5ce46afcb72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    891.000000\n",
              "mean      29.112424\n",
              "std       13.304424\n",
              "min        0.420000\n",
              "25%       21.500000\n",
              "50%       26.000000\n",
              "75%       36.000000\n",
              "max       80.000000\n",
              "Name: Age, dtype: float64"
            ]
          },
          "execution_count": 617,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['Age'].describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kzt2K3kojRC"
      },
      "source": [
        "Заполним пропуски в Embarked модальным значением."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 618,
      "metadata": {
        "id": "42d8YeQ5nzye"
      },
      "outputs": [],
      "source": [
        "data_train['Embarked'].fillna(data_train['Embarked'].value_counts().index[0], inplace = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YZXjPhcOS3je"
      },
      "source": [
        "Добавлю колонку Cabin_aviab показывающую было ли пропущено значение в колонке Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "metadata": {
        "id": "pvCrP0esoWg3"
      },
      "outputs": [],
      "source": [
        "# data_train['Cabin_aviab'] = np.where(data_train['Cabin'].isnull(), 0, 1)\n",
        "# data_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ik8pU_QlS3je"
      },
      "source": [
        "Преобразую колонку Cabin - Вместо кают A, B, C поставлю просто ABC и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 620,
      "metadata": {
        "id": "fc62TagDqsYk"
      },
      "outputs": [],
      "source": [
        "# data_train['Cabin'] = data_train['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
        "# # M - Miss\n",
        "# data_train[data_train[\"Cabin\"] == \"T\"]\n",
        "\n",
        "# data_train['Cabin'] = data_train['Cabin'].replace(['A', 'B', 'C'], 'ABC')\n",
        "# data_train['Cabin'] = data_train['Cabin'].replace(['D', 'E'], 'DE')\n",
        "# data_train['Cabin'] = data_train['Cabin'].replace(['F', 'G'], 'FG')\n",
        "\n",
        "# data_train['Cabin'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "id": "y8vG1GB0S3je"
      },
      "outputs": [],
      "source": [
        "def set_cabine(data_train):\n",
        "    data_train['Cabin_aviab'] = np.where(data_train['Cabin'].isnull(), 0, 1)\n",
        "    \n",
        "    data_train['Cabin'] = data_train['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
        "    # M - Miss\n",
        "    # data_train[data_train[\"Cabin\"] == \"T\"]\n",
        "\n",
        "    data_train['Cabin'] = data_train['Cabin'].replace(['A', 'B', 'C'], 'ABC')\n",
        "    data_train['Cabin'] = data_train['Cabin'].replace(['D', 'E', 'T'], 'DE')\n",
        "    data_train['Cabin'] = data_train['Cabin'].replace(['F', 'G'], 'FG')\n",
        "\n",
        "    return data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 622,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "Tsx8epDFS3je",
        "outputId": "f2ca4788-dc17-4b1f-e368-1cac343ef9fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Cabin_aviab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>21.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>M</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  21.5      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  Cabin_aviab  \n",
              "0        0         A/5 21171   7.2500     M        S            0  \n",
              "1        0          PC 17599  71.2833   ABC        C            1  \n",
              "2        0  STON/O2. 3101282   7.9250     M        S            0  \n",
              "3        0            113803  53.1000   ABC        S            1  \n",
              "4        0            373450   8.0500     M        S            0  \n",
              "..     ...               ...      ...   ...      ...          ...  \n",
              "886      0            211536  13.0000     M        S            0  \n",
              "887      0            112053  30.0000   ABC        S            1  \n",
              "888      2        W./C. 6607  23.4500     M        S            0  \n",
              "889      0            111369  30.0000   ABC        C            1  \n",
              "890      0            370376   7.7500     M        Q            0  \n",
              "\n",
              "[891 rows x 13 columns]"
            ]
          },
          "execution_count": 622,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_cabine(data_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yls-pP7wS3je"
      },
      "source": [
        "Попробуем поработать с титулами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 623,
      "metadata": {
        "id": "dpxNplMrS3jf"
      },
      "outputs": [],
      "source": [
        "def set_title(data_train):\n",
        "    data_train['Title'] = data_train['Name'].apply(lambda x: x.split('.')[0].split(',')[1].strip())\n",
        "    title = data_train['Title'].value_counts()[:9].index.tolist()\n",
        "\n",
        "    data_train['Title'] = data_train['Title'].apply(lambda x: x if x in title else 'other')\n",
        "\n",
        "    return data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 624,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "a9s0strhS3jf",
        "outputId": "c5bee234-730e-48b5-ec5f-6f4882f5df56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Cabin_aviab</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Rev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>21.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>M</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  21.5      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  Cabin_aviab Title  \n",
              "0        0         A/5 21171   7.2500     M        S            0    Mr  \n",
              "1        0          PC 17599  71.2833   ABC        C            1   Mrs  \n",
              "2        0  STON/O2. 3101282   7.9250     M        S            0  Miss  \n",
              "3        0            113803  53.1000   ABC        S            1   Mrs  \n",
              "4        0            373450   8.0500     M        S            0    Mr  \n",
              "..     ...               ...      ...   ...      ...          ...   ...  \n",
              "886      0            211536  13.0000     M        S            0   Rev  \n",
              "887      0            112053  30.0000   ABC        S            1  Miss  \n",
              "888      2        W./C. 6607  23.4500     M        S            0  Miss  \n",
              "889      0            111369  30.0000   ABC        C            1    Mr  \n",
              "890      0            370376   7.7500     M        Q            0    Mr  \n",
              "\n",
              "[891 rows x 14 columns]"
            ]
          },
          "execution_count": 624,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_title(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "metadata": {
        "id": "YcgVwnrCC164"
      },
      "outputs": [],
      "source": [
        "# data_train['Title'] = data_train['Name'].apply(lambda x: x.split('.')[0].split(',')[1].strip())\n",
        "# title = data_train['Title'].value_counts()[:9].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 626,
      "metadata": {
        "id": "SORB5fFlS3jf"
      },
      "outputs": [],
      "source": [
        "# data_train['Title'] = data_train['Title'].apply(lambda x: x if x in title else 'other')\n",
        "# data_train['Title'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yMM3ISyWS3jf"
      },
      "source": [
        "Посмотрим на билеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 627,
      "metadata": {
        "id": "fYRqW4t_S3jf"
      },
      "outputs": [],
      "source": [
        "def set_fr_tic(data_train):\n",
        "    frequency_ticket = data_train['Ticket'].value_counts().sort_values(ascending=True).reset_index()\n",
        "    frequency_ticket.columns = ['Ticket', 'Frequency_Ticket']\n",
        "\n",
        "    data_train = data_train.merge(frequency_ticket, on='Ticket', how='left')\n",
        "\n",
        "    return data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 628,
      "metadata": {
        "id": "w_D0SDE4S3jf"
      },
      "outputs": [],
      "source": [
        "data_train = set_fr_tic(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 629,
      "metadata": {
        "id": "jUDjWrZ-S3jf"
      },
      "outputs": [],
      "source": [
        "# data_train['Ticket'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 630,
      "metadata": {
        "id": "tQQde2jGS3jg"
      },
      "outputs": [],
      "source": [
        "# frequency_ticket = data_train['Ticket'].value_counts().sort_values(ascending=True).reset_index()\n",
        "# frequency_ticket.columns = ['Ticket', 'Frequency_Ticket']\n",
        "\n",
        "# data_train = data_train.merge(frequency_ticket, on='Ticket', how='left')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Ir29_5S3jg"
      },
      "source": [
        "Размер семьи \\ путешествует один"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 631,
      "metadata": {
        "id": "oyYF05SgS3jg"
      },
      "outputs": [],
      "source": [
        "def set_fem_size(data_train):\n",
        "    data_train['Family_size'] = data_train['SibSp'] + data_train['Parch'] + 1\n",
        "    data_train['is_alone'] = np.where(data_train['Family_size'] == 1, 1, 0)\n",
        "    \n",
        "    return data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 632,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "MLQJ0fCES3jg",
        "outputId": "6ed73483-fdd5-47f4-f634-4ecb5b888a2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Cabin_aviab</th>\n",
              "      <th>Title</th>\n",
              "      <th>Frequency_Ticket</th>\n",
              "      <th>Family_size</th>\n",
              "      <th>is_alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Rev</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>21.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>M</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  21.5      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  Cabin_aviab Title  \\\n",
              "0        0         A/5 21171   7.2500     M        S            0    Mr   \n",
              "1        0          PC 17599  71.2833   ABC        C            1   Mrs   \n",
              "2        0  STON/O2. 3101282   7.9250     M        S            0  Miss   \n",
              "3        0            113803  53.1000   ABC        S            1   Mrs   \n",
              "4        0            373450   8.0500     M        S            0    Mr   \n",
              "..     ...               ...      ...   ...      ...          ...   ...   \n",
              "886      0            211536  13.0000     M        S            0   Rev   \n",
              "887      0            112053  30.0000   ABC        S            1  Miss   \n",
              "888      2        W./C. 6607  23.4500     M        S            0  Miss   \n",
              "889      0            111369  30.0000   ABC        C            1    Mr   \n",
              "890      0            370376   7.7500     M        Q            0    Mr   \n",
              "\n",
              "     Frequency_Ticket  Family_size  is_alone  \n",
              "0                   1            2         0  \n",
              "1                   1            2         0  \n",
              "2                   1            1         1  \n",
              "3                   2            2         0  \n",
              "4                   1            1         1  \n",
              "..                ...          ...       ...  \n",
              "886                 1            1         1  \n",
              "887                 1            1         1  \n",
              "888                 2            4         0  \n",
              "889                 1            1         1  \n",
              "890                 1            1         1  \n",
              "\n",
              "[891 rows x 17 columns]"
            ]
          },
          "execution_count": 632,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set_fem_size(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 633,
      "metadata": {
        "id": "-H7DTtAKS3jg"
      },
      "outputs": [],
      "source": [
        "# data_train['Family_size'] = data_train['SibSp'] + data_train['Parch'] + 1\n",
        "# data_train['is_alone'] = np.where(data_train['Family_size'] == 1, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 634,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "4KAMiB6WS3jg",
        "outputId": "a170d589-9a6f-46c1-96ee-21692b6e4b2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Cabin_aviab</th>\n",
              "      <th>Title</th>\n",
              "      <th>Frequency_Ticket</th>\n",
              "      <th>Family_size</th>\n",
              "      <th>is_alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Rev</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>21.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>M</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  21.5      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  Cabin_aviab Title  \\\n",
              "0        0         A/5 21171   7.2500     M        S            0    Mr   \n",
              "1        0          PC 17599  71.2833   ABC        C            1   Mrs   \n",
              "2        0  STON/O2. 3101282   7.9250     M        S            0  Miss   \n",
              "3        0            113803  53.1000   ABC        S            1   Mrs   \n",
              "4        0            373450   8.0500     M        S            0    Mr   \n",
              "..     ...               ...      ...   ...      ...          ...   ...   \n",
              "886      0            211536  13.0000     M        S            0   Rev   \n",
              "887      0            112053  30.0000   ABC        S            1  Miss   \n",
              "888      2        W./C. 6607  23.4500     M        S            0  Miss   \n",
              "889      0            111369  30.0000   ABC        C            1    Mr   \n",
              "890      0            370376   7.7500     M        Q            0    Mr   \n",
              "\n",
              "     Frequency_Ticket  Family_size  is_alone  \n",
              "0                   1            2         0  \n",
              "1                   1            2         0  \n",
              "2                   1            1         1  \n",
              "3                   2            2         0  \n",
              "4                   1            1         1  \n",
              "..                ...          ...       ...  \n",
              "886                 1            1         1  \n",
              "887                 1            1         1  \n",
              "888                 2            4         0  \n",
              "889                 1            1         1  \n",
              "890                 1            1         1  \n",
              "\n",
              "[891 rows x 17 columns]"
            ]
          },
          "execution_count": 634,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UJRLrxXvS3j0"
      },
      "source": [
        "На этом , пока что, работа с признаками закончена."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "boLJGO5PS3j1"
      },
      "source": [
        "Категориальные переменные попробуем передать в catboost без изменения, что бы закодировал сам"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oHzIPv5lS3j1"
      },
      "source": [
        "Удалю ненужные колонки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {
        "id": "VRqD8AEbS3j1"
      },
      "outputs": [],
      "source": [
        "y = data_train['Survived']\n",
        "data_train = data_train.drop(['PassengerId', 'Name', 'Ticket', 'Survived'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {
        "id": "nUEnT9b9S3j1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 637,
      "metadata": {
        "id": "-cKc9kzeS3j1"
      },
      "outputs": [],
      "source": [
        "X = data_train\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 638,
      "metadata": {
        "id": "CTAIezxtS3j1"
      },
      "outputs": [],
      "source": [
        "num_columns = X.select_dtypes('float').columns.tolist()\n",
        "cat_columns = X.drop(num_columns, axis=1).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 639,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXwBeXZCTIsY",
        "outputId": "ee6fdf84-eb79-4183-ff6e-58e6b8db6c40"
      },
      "outputs": [],
      "source": [
        "# pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 640,
      "metadata": {
        "id": "JHOQUI8sS3j1"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 641,
      "metadata": {
        "id": "8fcg0azTS3j2"
      },
      "outputs": [],
      "source": [
        "# from sklearn.pipeline import Pipeline, make_pipeline, FunctionTransformer\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# age = FunctionTransformer(set_age(data_train))\n",
        "# cabine = FunctionTransformer(set_cabine(data_train))\n",
        "# title = FunctionTransformer(set_title(data_train))\n",
        "# fam_size = FunctionTransformer(set_fem_size(data_train))\n",
        "# fr_tic = FunctionTransformer(set_fr_tic(data_train))\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('age', age),\n",
        "#     ('cabine', cabine),\n",
        "#     ('title', title),\n",
        "#     ('fam_size', fam_size),\n",
        "#     (\"fr_tic\", fr_tic)\n",
        "# ])\n",
        "\n",
        "# num = Pipeline([\n",
        "#     ('scaler', StandardScaler())\n",
        "# ])\n",
        "\n",
        "# col_trans = ColumnTransformer([\n",
        "#     ('pipe', pipe, X.columns),\n",
        "#     ('num', num, num_columns)\n",
        "# ])\n",
        "\n",
        "# col_trans.fit_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 642,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.loc[X['Fare'] > 500, 'Fare'] = 60.2875"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 643,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Cabin_aviab</th>\n",
              "      <th>Title</th>\n",
              "      <th>Frequency_Ticket</th>\n",
              "      <th>Family_size</th>\n",
              "      <th>is_alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>19.00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>146.5208</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>23.00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>247.5208</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>58.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146.5208</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>31.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113.2750</td>\n",
              "      <td>DE</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>58.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>153.4625</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>135.6333</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>50.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>247.5208</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Master</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>M</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>17.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>18.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>262.3750</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>31.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>164.8667</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>40.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>134.5000</td>\n",
              "      <td>DE</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>36.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>135.6333</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>38.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>153.4625</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>133.6500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>41.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>134.5000</td>\n",
              "      <td>DE</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>24.00</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>135.6333</td>\n",
              "      <td>M</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>27.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>211.5000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>42.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>M</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>36.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>23.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113.2750</td>\n",
              "      <td>DE</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>14.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>64.00</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>25.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>18.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>40.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221.7792</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>30.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>106.4250</td>\n",
              "      <td>M</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>50.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>106.4250</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>17.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>40.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>M</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>39.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>40.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>153.4625</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>58.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>113.2750</td>\n",
              "      <td>DE</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>50.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>133.6500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Dr</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>15.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>49.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>18.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>29.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>21.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>262.3750</td>\n",
              "      <td>ABC</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>Miss</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>36.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>43.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>11.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>ABC</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Master</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>45.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>164.8667</td>\n",
              "      <td>M</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex    Age  SibSp  Parch      Fare Cabin Embarked  \\\n",
              "27        1    male  19.00      3      2  263.0000   ABC        S   \n",
              "31        1  female  35.00      1      0  146.5208   ABC        C   \n",
              "88        1  female  23.00      3      2  263.0000   ABC        S   \n",
              "118       1    male  24.00      0      1  247.5208   ABC        C   \n",
              "195       1  female  58.00      0      0  146.5208   ABC        C   \n",
              "215       1  female  31.00      1      0  113.2750    DE        C   \n",
              "268       1  female  58.00      0      1  153.4625   ABC        S   \n",
              "269       1  female  35.00      0      0  135.6333   ABC        S   \n",
              "297       1  female   2.00      1      2  151.5500   ABC        S   \n",
              "299       1  female  50.00      0      1  247.5208   ABC        C   \n",
              "305       1    male   0.92      1      2  151.5500   ABC        S   \n",
              "306       1  female  35.00      0      0  110.8833     M        C   \n",
              "307       1  female  17.00      1      0  108.9000   ABC        C   \n",
              "311       1  female  18.00      2      2  262.3750   ABC        C   \n",
              "318       1  female  31.00      0      2  164.8667   ABC        S   \n",
              "319       1  female  40.00      1      1  134.5000    DE        C   \n",
              "325       1  female  36.00      0      0  135.6333   ABC        C   \n",
              "332       1    male  38.00      0      1  153.4625   ABC        S   \n",
              "334       1  female  35.00      1      0  133.6500     M        S   \n",
              "337       1  female  41.00      0      0  134.5000    DE        C   \n",
              "341       1  female  24.00      3      2  263.0000   ABC        S   \n",
              "373       1    male  22.00      0      0  135.6333     M        C   \n",
              "377       1    male  27.00      0      2  211.5000   ABC        C   \n",
              "380       1  female  42.00      0      0  227.5250     M        C   \n",
              "390       1    male  36.00      1      2  120.0000   ABC        S   \n",
              "393       1  female  23.00      1      0  113.2750    DE        C   \n",
              "435       1  female  14.00      1      2  120.0000   ABC        S   \n",
              "438       1    male  64.00      1      4  263.0000   ABC        S   \n",
              "498       1  female  25.00      1      2  151.5500   ABC        S   \n",
              "505       1    male  18.00      1      0  108.9000   ABC        C   \n",
              "527       1    male  40.00      0      0  221.7792   ABC        S   \n",
              "537       1  female  30.00      0      0  106.4250     M        C   \n",
              "544       1    male  50.00      1      0  106.4250   ABC        C   \n",
              "550       1    male  17.00      0      2  110.8833   ABC        C   \n",
              "557       1    male  40.00      0      0  227.5250     M        C   \n",
              "581       1  female  39.00      1      1  110.8833   ABC        C   \n",
              "609       1  female  40.00      0      0  153.4625   ABC        S   \n",
              "659       1    male  58.00      0      2  113.2750    DE        C   \n",
              "660       1    male  50.00      2      0  133.6500     M        S   \n",
              "689       1  female  15.00      0      1  211.3375   ABC        S   \n",
              "698       1    male  49.00      1      1  110.8833   ABC        C   \n",
              "700       1  female  18.00      1      0  227.5250   ABC        C   \n",
              "708       1  female  22.00      0      0  151.5500     M        S   \n",
              "716       1  female  38.00      0      0  227.5250   ABC        C   \n",
              "730       1  female  29.00      0      0  211.3375   ABC        S   \n",
              "742       1  female  21.00      2      2  262.3750   ABC        C   \n",
              "763       1  female  36.00      1      2  120.0000   ABC        S   \n",
              "779       1  female  43.00      0      1  211.3375   ABC        S   \n",
              "802       1    male  11.00      1      2  120.0000   ABC        S   \n",
              "856       1  female  45.00      1      1  164.8667     M        S   \n",
              "\n",
              "     Cabin_aviab   Title  Frequency_Ticket  Family_size  is_alone  \n",
              "27             1      Mr                 4            6         0  \n",
              "31             1     Mrs                 2            2         0  \n",
              "88             1    Miss                 4            6         0  \n",
              "118            1      Mr                 2            2         0  \n",
              "195            1    Miss                 2            1         1  \n",
              "215            1    Miss                 3            2         0  \n",
              "268            1     Mrs                 3            2         0  \n",
              "269            1    Miss                 3            1         1  \n",
              "297            1    Miss                 4            4         0  \n",
              "299            1     Mrs                 2            2         0  \n",
              "305            1  Master                 4            4         0  \n",
              "306            0    Miss                 4            1         1  \n",
              "307            1     Mrs                 2            2         0  \n",
              "311            1    Miss                 2            5         0  \n",
              "318            1    Miss                 2            3         0  \n",
              "319            1     Mrs                 2            3         0  \n",
              "325            1    Miss                 3            1         1  \n",
              "332            1      Mr                 3            2         0  \n",
              "334            0     Mrs                 2            2         0  \n",
              "337            1    Miss                 2            1         1  \n",
              "341            1    Miss                 4            6         0  \n",
              "373            0      Mr                 3            1         1  \n",
              "377            1      Mr                 1            3         0  \n",
              "380            0    Miss                 4            1         1  \n",
              "390            1      Mr                 4            4         0  \n",
              "393            1    Miss                 3            2         0  \n",
              "435            1    Miss                 4            4         0  \n",
              "438            1      Mr                 4            6         0  \n",
              "498            1     Mrs                 4            4         0  \n",
              "505            1      Mr                 2            2         0  \n",
              "527            1      Mr                 1            1         1  \n",
              "537            0    Miss                 2            1         1  \n",
              "544            1      Mr                 2            2         0  \n",
              "550            1      Mr                 4            3         0  \n",
              "557            0      Mr                 4            1         1  \n",
              "581            1     Mrs                 4            3         0  \n",
              "609            1    Miss                 3            1         1  \n",
              "659            1      Mr                 3            3         0  \n",
              "660            0      Dr                 2            3         0  \n",
              "689            1    Miss                 3            2         0  \n",
              "698            1      Mr                 4            3         0  \n",
              "700            1     Mrs                 4            2         0  \n",
              "708            0    Miss                 4            1         1  \n",
              "716            1    Miss                 4            1         1  \n",
              "730            1    Miss                 3            1         1  \n",
              "742            1    Miss                 2            5         0  \n",
              "763            1     Mrs                 4            4         0  \n",
              "779            1     Mrs                 3            2         0  \n",
              "802            1  Master                 4            4         0  \n",
              "856            0     Mrs                 2            3         0  "
            ]
          },
          "execution_count": 643,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[X['Fare'] > 100 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 644,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gosha\\AppData\\Local\\Temp\\ipykernel_9228\\3932931358.py:1: FutureWarning: ['Sex', 'Embarked', 'Title'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
            "  X.groupby(['Pclass', 'Cabin']).agg(['mean', 'median', 'min', 'max', 'std', 'count'])['Fare']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>median</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <th>Cabin</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
              "      <th>ABC</th>\n",
              "      <td>90.363429</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>68.022816</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DE</th>\n",
              "      <td>59.371064</td>\n",
              "      <td>55.0000</td>\n",
              "      <td>25.5875</td>\n",
              "      <td>134.5000</td>\n",
              "      <td>28.117811</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>65.547600</td>\n",
              "      <td>44.7500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>56.002796</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
              "      <th>DE</th>\n",
              "      <td>12.377088</td>\n",
              "      <td>12.9375</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>13.7917</td>\n",
              "      <td>1.222454</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FG</th>\n",
              "      <td>23.750000</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>39.0000</td>\n",
              "      <td>11.631239</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>20.909673</td>\n",
              "      <td>15.0229</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>73.5000</td>\n",
              "      <td>13.701631</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
              "      <th>DE</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>12.4750</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>12.4750</td>\n",
              "      <td>2.554775</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FG</th>\n",
              "      <td>11.931478</td>\n",
              "      <td>10.4625</td>\n",
              "      <td>7.6500</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>5.373429</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>13.725077</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>69.5500</td>\n",
              "      <td>11.899245</td>\n",
              "      <td>479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   mean   median      min       max        std  count\n",
              "Pclass Cabin                                                         \n",
              "1      ABC    90.363429  71.2833   0.0000  263.0000  68.022816    121\n",
              "       DE     59.371064  55.0000  25.5875  134.5000  28.117811     55\n",
              "       M      65.547600  44.7500   0.0000  227.5250  56.002796     40\n",
              "2      DE     12.377088  12.9375  10.5000   13.7917   1.222454      8\n",
              "       FG     23.750000  26.0000  10.5000   39.0000  11.631239      8\n",
              "       M      20.909673  15.0229   0.0000   73.5000  13.701631    168\n",
              "3      DE     11.000000  12.4750   8.0500   12.4750   2.554775      3\n",
              "       FG     11.931478  10.4625   7.6500   22.3583   5.373429      9\n",
              "       M      13.725077   8.0500   0.0000   69.5500  11.899245    479"
            ]
          },
          "execution_count": 644,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.groupby(['Pclass', 'Cabin']).agg(['mean', 'median', 'min', 'max', 'std', 'count'])['Fare']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 645,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_cabine_2(data):\n",
        "    data1 = data.copy()\n",
        "    \n",
        "    data1.loc[(data1['Fare'] >= 65) & (data1['Cabin'] == 'M') & (data1['Pclass'] == 1), 'Cabin'] = 'ABC'\n",
        "    data1.loc[(data1['Pclass'] == 1) & (data1['Fare'] < 65) & (data1['Cabin'] == 'M'), 'Cabin'] = 'DE'\n",
        "\n",
        "    data1.loc[(data1['Fare'] <= 13.7) & (data1['Cabin'] == 'M') & (data1['Pclass'] == 2), 'Cabin'] = 'DE'\n",
        "    data1.loc[(data1['Fare'] > 13.7) & (data1['Cabin'] == 'M') & (data1['Pclass'] == 2), 'Cabin'] = 'FG'\n",
        "\n",
        "    data1.loc[(data1['Cabin'] == 'M') & (data1['Pclass'] == 3) & (data1['Fare'] >= 12.5), 'Cabin'] = 'FG'\n",
        "    data1.loc[(data1['Cabin'] == 'M') & (data1['Pclass'] == 3) & (data1['Fare'] < 12.5), 'Cabin'] = 'DE'\n",
        "\n",
        "    return data1\n",
        "\n",
        "\n",
        "X = set_cabine_2(X)\n",
        "# N['Cabin'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 646,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DE     500\n",
              "FG     257\n",
              "ABC    134\n",
              "Name: Cabin, dtype: int64"
            ]
          },
          "execution_count": 646,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Cabin'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 647,
      "metadata": {
        "id": "h40P0RgZS3j2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def scaler(data, num_columns):\n",
        "    scaler = StandardScaler()\n",
        "    data[num_columns] = scaler.fit_transform(data[num_columns])\n",
        "    # return data\n",
        "\n",
        "scaler(X, num_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 648,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fng5TX5ITN1M",
        "outputId": "f75ae25f-1709-4ea0-84f2-1b98e0f3bf78"
      },
      "outputs": [],
      "source": [
        "# pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 649,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9UWayrdS3j2",
        "outputId": "7d96514f-4b75-490c-910f-575c2b8adfe3"
      },
      "outputs": [],
      "source": [
        "# import optuna\n",
        "# from optuna.samplers import TPESampler\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def objective(trial):\n",
        "#     param = {\n",
        "#         'learning_rate':trial.suggest_float('learning_rate',0.001,1),\n",
        "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 5),\n",
        "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.01, 10),\n",
        "#         \"n_estimators\" : trial.suggest_int('n_estimators', 10, 1500, 10),\n",
        "#         'depth': trial.suggest_int('depth', 1, 16, 1)\n",
        "#     }\n",
        "\n",
        "#     model = CatBoostClassifier(silent=True, **param, cat_features=cat_columns, random_strength=1)\n",
        "#     # return model.score(X_test, y_test)\n",
        "#     return  cross_val_score(model, X_train, y_train, scoring = 'accuracy', cv=5, n_jobs=-1).mean()\n",
        "\n",
        "# study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
        "# study.optimize(lambda trial : objective(trial),n_trials=200, n_jobs=-1)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 650,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "#         'learning_rate':trial.suggest_float('learning_rate',0.001,1),\n",
        "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "#         'lambda': trial.suggest_float('lambda', 0.0, 10),\n",
        "#         \"n_estimators\" : trial.suggest_int('n_estimators', 10, 100, 10),"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Xgbooost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 651,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install xgboost\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 652,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 653,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "# new_X = encoder.fit_transform(X[cat_columns])\n",
        "# pd.DataFrame(new_X, columns=encoder.get_feature_names_out().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 654,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nn = pd.concat([pd.DataFrame(new_X, columns=encoder.get_feature_names_out().tolist()), X[num_columns]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 655,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode(data, cat_columns, num_columns):\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "    new_data = encoder.fit_transform(data[cat_columns])\n",
        "    data = pd.concat([pd.DataFrame(new_data, columns=encoder.get_feature_names_out().tolist()), data[num_columns]], axis=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "X = encode(X, cat_columns, num_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 656,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install -U imbalanced-learn\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 657,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smote(X, y):\n",
        "    # from imblearn.over_sampling import SMOTE\n",
        "\n",
        "    sm = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=10)\n",
        "    X_sm, y_sm = sm.fit_resample(X,y)\n",
        "\n",
        "    return X_sm, y_sm\n",
        "\n",
        "X, y = smote(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 658,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adasyn(X, y):\n",
        "    # from imblearn.over_sampling import SMOTE\n",
        "\n",
        "    sm = ADASYN(random_state=42, n_neighbors=10, n_jobs=-1)\n",
        "    X_sm, y_sm = sm.fit_resample(X,y)\n",
        "\n",
        "    return X_sm, y_sm\n",
        "\n",
        "# X, y = adasyn(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 659,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 660,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 661,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8361519302615192"
            ]
          },
          "execution_count": 661,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = XGBClassifier()\n",
        "\n",
        "cross_val_score(model, X, y, scoring = 'accuracy', cv=5, n_jobs=-1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 662,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8036363636363636"
            ]
          },
          "execution_count": 662,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "mod_pred = model.predict(X_test)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 663,
      "metadata": {},
      "outputs": [],
      "source": [
        "ex = pd.Series(model.feature_importances_, index=X.columns) > 0\n",
        "names = pd.Series(model.feature_importances_, index=X.columns)[ex].index.tolist()\n",
        "names\n",
        "X = X[names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 664,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-10 13:35:51,136] A new study created in memory with name: no-name-f38d5dfd-2df3-4011-8939-28d1122b5d66\n",
            "[I 2023-06-10 13:35:55,094] Trial 0 finished with value: 0.8325271059216013 and parameters: {'learning_rate': 0.547410213288808, 'min_child_weight': 4, 'lambda': 6.601786852209733, 'n_estimators': 999, 'max_depth': 3}. Best is trial 0 with value: 0.8325271059216013.\n",
            "[I 2023-06-10 13:36:06,025] Trial 1 finished with value: 0.8362051709758133 and parameters: {'learning_rate': 0.3181595323593516, 'min_child_weight': 1, 'lambda': 5.895856362804782, 'n_estimators': 492, 'max_depth': 14}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:07,866] Trial 3 finished with value: 0.8288907422852377 and parameters: {'learning_rate': 0.9932504018206525, 'min_child_weight': 2, 'lambda': 4.834686745164796, 'n_estimators': 891, 'max_depth': 14}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:07,925] Trial 2 finished with value: 0.8270892410341952 and parameters: {'learning_rate': 0.6455308949673492, 'min_child_weight': 3, 'lambda': 2.2499409704190994, 'n_estimators': 458, 'max_depth': 14}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:09,834] Trial 7 finished with value: 0.826180150125104 and parameters: {'learning_rate': 0.7553142637386325, 'min_child_weight': 1, 'lambda': 5.709004805494437, 'n_estimators': 1086, 'max_depth': 4}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:09,915] Trial 9 finished with value: 0.826188490408674 and parameters: {'learning_rate': 0.6309196144776765, 'min_child_weight': 4, 'lambda': 3.1614994844988518, 'n_estimators': 1213, 'max_depth': 4}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:10,108] Trial 10 finished with value: 0.8261801501251043 and parameters: {'learning_rate': 0.20887479007748194, 'min_child_weight': 1, 'lambda': 5.431923048568707, 'n_estimators': 558, 'max_depth': 7}. Best is trial 1 with value: 0.8362051709758133.\n",
            "[I 2023-06-10 13:36:10,237] Trial 4 finished with value: 0.8398248540450375 and parameters: {'learning_rate': 0.3078009404378684, 'min_child_weight': 2, 'lambda': 8.946834331017884, 'n_estimators': 1411, 'max_depth': 2}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:11,000] Trial 5 finished with value: 0.8298248540450375 and parameters: {'learning_rate': 0.7423189796255709, 'min_child_weight': 5, 'lambda': 2.7863294319594227, 'n_estimators': 470, 'max_depth': 20}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:11,318] Trial 11 finished with value: 0.8325437864887405 and parameters: {'learning_rate': 0.9962530387724811, 'min_child_weight': 5, 'lambda': 9.508070347378714, 'n_estimators': 745, 'max_depth': 5}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:11,774] Trial 6 finished with value: 0.8307005838198499 and parameters: {'learning_rate': 0.06869825828300495, 'min_child_weight': 4, 'lambda': 7.537649530031441, 'n_estimators': 1232, 'max_depth': 8}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:13,174] Trial 8 finished with value: 0.825254378648874 and parameters: {'learning_rate': 0.8137866916950631, 'min_child_weight': 3, 'lambda': 0.12058561325356325, 'n_estimators': 1327, 'max_depth': 11}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:15,307] Trial 13 finished with value: 0.8397664720600501 and parameters: {'learning_rate': 0.03968843788361725, 'min_child_weight': 3, 'lambda': 4.511682345904232, 'n_estimators': 248, 'max_depth': 13}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:15,915] Trial 12 finished with value: 0.8270892410341952 and parameters: {'learning_rate': 0.1879329750204841, 'min_child_weight': 2, 'lambda': 4.763555418832739, 'n_estimators': 990, 'max_depth': 15}. Best is trial 4 with value: 0.8398248540450375.\n",
            "[I 2023-06-10 13:36:16,441] Trial 15 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.06326582815522999, 'min_child_weight': 4, 'lambda': 7.957771203879422, 'n_estimators': 146, 'max_depth': 5}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:16,490] Trial 14 finished with value: 0.8388573811509593 and parameters: {'learning_rate': 0.028810931147992103, 'min_child_weight': 4, 'lambda': 5.505707850695704, 'n_estimators': 320, 'max_depth': 20}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:20,532] Trial 16 finished with value: 0.831651376146789 and parameters: {'learning_rate': 0.20607369267746445, 'min_child_weight': 1, 'lambda': 5.7668147507967795, 'n_estimators': 1117, 'max_depth': 18}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:21,848] Trial 17 finished with value: 0.830742285237698 and parameters: {'learning_rate': 0.7673080364985325, 'min_child_weight': 5, 'lambda': 5.728893538505068, 'n_estimators': 1038, 'max_depth': 4}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:25,080] Trial 18 finished with value: 0.8298165137614679 and parameters: {'learning_rate': 0.37507056645268627, 'min_child_weight': 4, 'lambda': 3.146783160132251, 'n_estimators': 1352, 'max_depth': 16}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:25,299] Trial 19 finished with value: 0.8361217681401168 and parameters: {'learning_rate': 0.04059337382406654, 'min_child_weight': 1, 'lambda': 1.1779285010731448, 'n_estimators': 744, 'max_depth': 4}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:26,381] Trial 20 finished with value: 0.822535446205171 and parameters: {'learning_rate': 0.7900531213203154, 'min_child_weight': 3, 'lambda': 0.7684948611216579, 'n_estimators': 564, 'max_depth': 10}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:26,964] Trial 22 finished with value: 0.8297497914929106 and parameters: {'learning_rate': 0.3578251283393831, 'min_child_weight': 2, 'lambda': 0.30774527480637115, 'n_estimators': 37, 'max_depth': 13}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:27,079] Trial 23 finished with value: 0.8306755629691409 and parameters: {'learning_rate': 0.33953397010127495, 'min_child_weight': 2, 'lambda': 9.24233298758882, 'n_estimators': 12, 'max_depth': 18}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:27,207] Trial 24 finished with value: 0.7786989157631361 and parameters: {'learning_rate': 0.023067199373119848, 'min_child_weight': 2, 'lambda': 9.85303734350963, 'n_estimators': 64, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:27,279] Trial 25 finished with value: 0.7723352793994996 and parameters: {'learning_rate': 0.0050564779806258064, 'min_child_weight': 2, 'lambda': 9.932195562759267, 'n_estimators': 29, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:27,622] Trial 21 finished with value: 0.820600500417014 and parameters: {'learning_rate': 0.025698106490289196, 'min_child_weight': 2, 'lambda': 9.349996700913323, 'n_estimators': 1476, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:28,773] Trial 26 finished with value: 0.8388573811509591 and parameters: {'learning_rate': 0.3285314024956629, 'min_child_weight': 2, 'lambda': 9.766380938957873, 'n_estimators': 1493, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:28,870] Trial 28 finished with value: 0.7832693911592994 and parameters: {'learning_rate': 0.3853818251314264, 'min_child_weight': 2, 'lambda': 9.86406157693092, 'n_estimators': 13, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:28,990] Trial 29 finished with value: 0.8133194328607173 and parameters: {'learning_rate': 0.37340219899925065, 'min_child_weight': 2, 'lambda': 9.775250447100436, 'n_estimators': 17, 'max_depth': 2}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:29,230] Trial 30 finished with value: 0.8206005004170143 and parameters: {'learning_rate': 0.4051378928584023, 'min_child_weight': 2, 'lambda': 9.816335752550103, 'n_estimators': 82, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:29,448] Trial 31 finished with value: 0.8215179316096746 and parameters: {'learning_rate': 0.4066574023446642, 'min_child_weight': 2, 'lambda': 9.856161887746582, 'n_estimators': 81, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:29,624] Trial 32 finished with value: 0.786930775646372 and parameters: {'learning_rate': 0.10261277374298813, 'min_child_weight': 2, 'lambda': 8.916518864607099, 'n_estimators': 59, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:29,959] Trial 33 finished with value: 0.7978398665554629 and parameters: {'learning_rate': 0.11630561937688966, 'min_child_weight': 3, 'lambda': 9.511297284383325, 'n_estimators': 120, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:30,122] Trial 27 finished with value: 0.8388573811509591 and parameters: {'learning_rate': 0.38800274559993697, 'min_child_weight': 2, 'lambda': 9.493651224245768, 'n_estimators': 1488, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:30,204] Trial 34 finished with value: 0.8169474562135113 and parameters: {'learning_rate': 0.12427535345010399, 'min_child_weight': 3, 'lambda': 8.57528472669738, 'n_estimators': 211, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:30,316] Trial 35 finished with value: 0.8114929107589658 and parameters: {'learning_rate': 0.11485980065280466, 'min_child_weight': 3, 'lambda': 8.768820473456222, 'n_estimators': 190, 'max_depth': 1}. Best is trial 15 with value: 0.8415846538782319.\n",
            "[I 2023-06-10 13:36:30,996] Trial 36 finished with value: 0.8452210175145953 and parameters: {'learning_rate': 0.1259966463792841, 'min_child_weight': 3, 'lambda': 8.608025036637308, 'n_estimators': 230, 'max_depth': 7}. Best is trial 36 with value: 0.8452210175145953.\n",
            "[I 2023-06-10 13:36:31,696] Trial 37 finished with value: 0.8443202668890744 and parameters: {'learning_rate': 0.11595453461944549, 'min_child_weight': 3, 'lambda': 8.42983292872971, 'n_estimators': 250, 'max_depth': 7}. Best is trial 36 with value: 0.8452210175145953.\n",
            "[I 2023-06-10 13:36:32,255] Trial 38 finished with value: 0.8452210175145956 and parameters: {'learning_rate': 0.11979117315611898, 'min_child_weight': 3, 'lambda': 8.444198099795507, 'n_estimators': 202, 'max_depth': 7}. Best is trial 38 with value: 0.8452210175145956.\n",
            "[I 2023-06-10 13:36:33,005] Trial 39 finished with value: 0.8443202668890744 and parameters: {'learning_rate': 0.12455185288072465, 'min_child_weight': 3, 'lambda': 8.371297116606515, 'n_estimators': 270, 'max_depth': 7}. Best is trial 38 with value: 0.8452210175145956.\n",
            "[I 2023-06-10 13:36:33,663] Trial 40 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.107063849624318, 'min_child_weight': 3, 'lambda': 7.9495863909208415, 'n_estimators': 214, 'max_depth': 7}. Best is trial 38 with value: 0.8452210175145956.\n",
            "[I 2023-06-10 13:36:33,872] Trial 41 finished with value: 0.8461384487072561 and parameters: {'learning_rate': 0.12660599377794807, 'min_child_weight': 3, 'lambda': 8.067995614988535, 'n_estimators': 200, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:34,388] Trial 42 finished with value: 0.8379566305254379 and parameters: {'learning_rate': 0.12325512977798658, 'min_child_weight': 4, 'lambda': 8.089302484489554, 'n_estimators': 239, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:34,754] Trial 43 finished with value: 0.8425104253544621 and parameters: {'learning_rate': 0.10740158629832341, 'min_child_weight': 4, 'lambda': 7.3903545573203315, 'n_estimators': 206, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:35,404] Trial 44 finished with value: 0.8388740617180984 and parameters: {'learning_rate': 0.13285776549744083, 'min_child_weight': 4, 'lambda': 7.3300668448619675, 'n_estimators': 259, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:35,979] Trial 45 finished with value: 0.8406839032527106 and parameters: {'learning_rate': 0.1414244568421664, 'min_child_weight': 4, 'lambda': 6.922718049604821, 'n_estimators': 220, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:36,671] Trial 46 finished with value: 0.8334195162635532 and parameters: {'learning_rate': 0.2664271066292026, 'min_child_weight': 4, 'lambda': 6.662157050383309, 'n_estimators': 272, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:37,478] Trial 47 finished with value: 0.8316096747289408 and parameters: {'learning_rate': 0.26308627291857967, 'min_child_weight': 4, 'lambda': 6.690416648215224, 'n_estimators': 337, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:38,421] Trial 48 finished with value: 0.8379649708090076 and parameters: {'learning_rate': 0.27365234571674446, 'min_child_weight': 3, 'lambda': 7.9706827095982025, 'n_estimators': 341, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:39,037] Trial 49 finished with value: 0.8352460383653044 and parameters: {'learning_rate': 0.24143435362707621, 'min_child_weight': 4, 'lambda': 8.029661029938298, 'n_estimators': 387, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:40,013] Trial 50 finished with value: 0.8325104253544622 and parameters: {'learning_rate': 0.26640865146774617, 'min_child_weight': 4, 'lambda': 7.974928569793613, 'n_estimators': 375, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:40,869] Trial 51 finished with value: 0.8270391993327774 and parameters: {'learning_rate': 0.2632162246453137, 'min_child_weight': 3, 'lambda': 7.08648471590715, 'n_estimators': 371, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:42,005] Trial 52 finished with value: 0.8325187656380317 and parameters: {'learning_rate': 0.2568445125908856, 'min_child_weight': 3, 'lambda': 7.221363493767215, 'n_estimators': 379, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:42,989] Trial 53 finished with value: 0.8334528773978315 and parameters: {'learning_rate': 0.26387323446421884, 'min_child_weight': 3, 'lambda': 6.967493157272595, 'n_estimators': 361, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:43,989] Trial 54 finished with value: 0.8325271059216013 and parameters: {'learning_rate': 0.2366200048149889, 'min_child_weight': 3, 'lambda': 6.926157524192066, 'n_estimators': 337, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:44,832] Trial 55 finished with value: 0.8325020850708924 and parameters: {'learning_rate': 0.2557350515072507, 'min_child_weight': 3, 'lambda': 6.972924902746454, 'n_estimators': 363, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:45,611] Trial 56 finished with value: 0.8297914929107589 and parameters: {'learning_rate': 0.2517651721847707, 'min_child_weight': 3, 'lambda': 6.491235753117971, 'n_estimators': 369, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:46,822] Trial 57 finished with value: 0.8334278565471227 and parameters: {'learning_rate': 0.2646380481389332, 'min_child_weight': 3, 'lambda': 8.466244884121076, 'n_estimators': 371, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:47,870] Trial 58 finished with value: 0.8370558798999166 and parameters: {'learning_rate': 0.18314981755061172, 'min_child_weight': 3, 'lambda': 8.383009120827582, 'n_estimators': 382, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:48,925] Trial 59 finished with value: 0.8343119266055045 and parameters: {'learning_rate': 0.1715850715805745, 'min_child_weight': 3, 'lambda': 8.423655121775436, 'n_estimators': 391, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:50,267] Trial 60 finished with value: 0.8324937447873229 and parameters: {'learning_rate': 0.18717420221937972, 'min_child_weight': 3, 'lambda': 8.414823648922766, 'n_estimators': 431, 'max_depth': 10}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:51,285] Trial 61 finished with value: 0.8343202668890743 and parameters: {'learning_rate': 0.18185414903856778, 'min_child_weight': 3, 'lambda': 8.397055995103543, 'n_estimators': 443, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:52,682] Trial 62 finished with value: 0.8370391993327772 and parameters: {'learning_rate': 0.15684387542817266, 'min_child_weight': 3, 'lambda': 8.475817485055563, 'n_estimators': 458, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:53,865] Trial 63 finished with value: 0.8379649708090074 and parameters: {'learning_rate': 0.17268873415856778, 'min_child_weight': 3, 'lambda': 8.662944924470812, 'n_estimators': 455, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:55,154] Trial 64 finished with value: 0.8361384487072561 and parameters: {'learning_rate': 0.17193099615400667, 'min_child_weight': 3, 'lambda': 8.440318801606322, 'n_estimators': 456, 'max_depth': 10}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:56,676] Trial 65 finished with value: 0.8343286071726439 and parameters: {'learning_rate': 0.17571731775077226, 'min_child_weight': 3, 'lambda': 8.453182266764426, 'n_estimators': 529, 'max_depth': 9}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:57,196] Trial 66 finished with value: 0.8397831526271894 and parameters: {'learning_rate': 0.16484570048909097, 'min_child_weight': 3, 'lambda': 8.541262038775493, 'n_estimators': 496, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:58,373] Trial 67 finished with value: 0.8398081734778982 and parameters: {'learning_rate': 0.15747334901812565, 'min_child_weight': 5, 'lambda': 8.43715319017913, 'n_estimators': 556, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:36:59,071] Trial 68 finished with value: 0.8379816513761467 and parameters: {'learning_rate': 0.17284484867003644, 'min_child_weight': 5, 'lambda': 8.36874009623921, 'n_estimators': 473, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:00,619] Trial 69 finished with value: 0.8416096747289409 and parameters: {'learning_rate': 0.07310968814781704, 'min_child_weight': 5, 'lambda': 7.549594140799474, 'n_estimators': 536, 'max_depth': 11}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:01,576] Trial 70 finished with value: 0.8434195162635529 and parameters: {'learning_rate': 0.0693134940047676, 'min_child_weight': 5, 'lambda': 7.6549662978071975, 'n_estimators': 557, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:02,568] Trial 71 finished with value: 0.8425104253544621 and parameters: {'learning_rate': 0.0673204463744638, 'min_child_weight': 5, 'lambda': 7.689871225707519, 'n_estimators': 510, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:03,267] Trial 73 finished with value: 0.8397748123436196 and parameters: {'learning_rate': 0.07667411197664906, 'min_child_weight': 5, 'lambda': 7.542658505822006, 'n_estimators': 143, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:03,573] Trial 72 finished with value: 0.8434028356964138 and parameters: {'learning_rate': 0.060199457087443925, 'min_child_weight': 3, 'lambda': 7.642138384768605, 'n_estimators': 541, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:03,733] Trial 74 finished with value: 0.8397748123436196 and parameters: {'learning_rate': 0.07666533914112336, 'min_child_weight': 3, 'lambda': 7.704275916868332, 'n_estimators': 149, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:04,021] Trial 75 finished with value: 0.8434278565471226 and parameters: {'learning_rate': 0.0793316853178237, 'min_child_weight': 5, 'lambda': 7.534255500498569, 'n_estimators': 160, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:04,325] Trial 76 finished with value: 0.8425020850708924 and parameters: {'learning_rate': 0.07080148286555404, 'min_child_weight': 5, 'lambda': 7.7232324970960065, 'n_estimators': 158, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:04,693] Trial 77 finished with value: 0.8424854045037533 and parameters: {'learning_rate': 0.08192755467734508, 'min_child_weight': 3, 'lambda': 7.645013755331531, 'n_estimators': 156, 'max_depth': 5}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:04,941] Trial 78 finished with value: 0.8243035863219349 and parameters: {'learning_rate': 0.07050399842205884, 'min_child_weight': 5, 'lambda': 7.649950966768454, 'n_estimators': 165, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:05,378] Trial 79 finished with value: 0.8425020850708924 and parameters: {'learning_rate': 0.08403406507581591, 'min_child_weight': 5, 'lambda': 7.563133688409222, 'n_estimators': 146, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:05,773] Trial 80 finished with value: 0.8361384487072561 and parameters: {'learning_rate': 0.08562028472207338, 'min_child_weight': 3, 'lambda': 7.486130895390408, 'n_estimators': 295, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:05,885] Trial 81 finished with value: 0.8242869057547957 and parameters: {'learning_rate': 0.07923525630340379, 'min_child_weight': 3, 'lambda': 9.07471357506492, 'n_estimators': 160, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:06,165] Trial 82 finished with value: 0.8370391993327772 and parameters: {'learning_rate': 0.07728622895442525, 'min_child_weight': 5, 'lambda': 9.060639267401957, 'n_estimators': 159, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:06,557] Trial 83 finished with value: 0.8415929941618016 and parameters: {'learning_rate': 0.07965027484640506, 'min_child_weight': 5, 'lambda': 7.5505973074406665, 'n_estimators': 155, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:07,453] Trial 84 finished with value: 0.8388740617180984 and parameters: {'learning_rate': 0.050329362131244046, 'min_child_weight': 5, 'lambda': 9.147197276904873, 'n_estimators': 613, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:07,773] Trial 85 finished with value: 0.8279316096747289 and parameters: {'learning_rate': 0.04451002850178003, 'min_child_weight': 3, 'lambda': 9.056844260147333, 'n_estimators': 284, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:08,661] Trial 86 finished with value: 0.8452376980817347 and parameters: {'learning_rate': 0.08991532967645374, 'min_child_weight': 4, 'lambda': 8.973980879926021, 'n_estimators': 629, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:09,853] Trial 87 finished with value: 0.8379649708090074 and parameters: {'learning_rate': 0.040839646760596496, 'min_child_weight': 5, 'lambda': 9.099368621235158, 'n_estimators': 840, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:10,645] Trial 88 finished with value: 0.8260800667222685 and parameters: {'learning_rate': 0.005077640035909478, 'min_child_weight': 3, 'lambda': 9.067998673547898, 'n_estimators': 616, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:11,768] Trial 89 finished with value: 0.8288323603002501 and parameters: {'learning_rate': 0.0028449415890974133, 'min_child_weight': 3, 'lambda': 9.296666579695602, 'n_estimators': 612, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:12,736] Trial 90 finished with value: 0.82790658882402 and parameters: {'learning_rate': 0.001903160885393454, 'min_child_weight': 3, 'lambda': 8.903240813605601, 'n_estimators': 676, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:13,456] Trial 91 finished with value: 0.8215346121768141 and parameters: {'learning_rate': 0.006924256253051139, 'min_child_weight': 3, 'lambda': 9.207445496930774, 'n_estimators': 589, 'max_depth': 3}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:14,868] Trial 92 finished with value: 0.8288407005838199 and parameters: {'learning_rate': 0.004095145911401199, 'min_child_weight': 4, 'lambda': 8.979796201601182, 'n_estimators': 635, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:16,285] Trial 93 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.030787380362970587, 'min_child_weight': 4, 'lambda': 8.844057850210396, 'n_estimators': 636, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:17,494] Trial 94 finished with value: 0.8415929941618016 and parameters: {'learning_rate': 0.04009590862842072, 'min_child_weight': 4, 'lambda': 8.757256336603632, 'n_estimators': 608, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:19,214] Trial 95 finished with value: 0.8406922435362801 and parameters: {'learning_rate': 0.03993739088587232, 'min_child_weight': 4, 'lambda': 8.806147940581493, 'n_estimators': 694, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:20,687] Trial 96 finished with value: 0.8288407005838199 and parameters: {'learning_rate': 0.0017311997956802466, 'min_child_weight': 4, 'lambda': 8.931374707612562, 'n_estimators': 661, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:22,405] Trial 97 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.016102472857281974, 'min_child_weight': 4, 'lambda': 8.894888039163085, 'n_estimators': 689, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:23,804] Trial 99 finished with value: 0.8014678899082568 and parameters: {'learning_rate': 0.005905953913101433, 'min_child_weight': 4, 'lambda': 8.848613819074776, 'n_estimators': 651, 'max_depth': 2}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:24,155] Trial 98 finished with value: 0.8270225187656381 and parameters: {'learning_rate': 0.003856631249552281, 'min_child_weight': 4, 'lambda': 8.92718830506034, 'n_estimators': 666, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:25,779] Trial 100 finished with value: 0.8352627189324437 and parameters: {'learning_rate': 0.13654156688519697, 'min_child_weight': 4, 'lambda': 8.815130320005755, 'n_estimators': 679, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:26,052] Trial 101 finished with value: 0.8406922435362801 and parameters: {'learning_rate': 0.13701527186020157, 'min_child_weight': 4, 'lambda': 8.804578223430338, 'n_estimators': 686, 'max_depth': 2}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:26,076] Trial 102 finished with value: 0.8425020850708924 and parameters: {'learning_rate': 0.133297238318834, 'min_child_weight': 4, 'lambda': 8.140006181847436, 'n_estimators': 91, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:26,711] Trial 103 finished with value: 0.8388740617180984 and parameters: {'learning_rate': 0.14136009995396284, 'min_child_weight': 4, 'lambda': 8.137337707929156, 'n_estimators': 235, 'max_depth': 6}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:27,008] Trial 104 finished with value: 0.8424854045037531 and parameters: {'learning_rate': 0.10643945875815179, 'min_child_weight': 4, 'lambda': 8.223595700393302, 'n_estimators': 96, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:29,687] Trial 105 finished with value: 0.8388907422852376 and parameters: {'learning_rate': 0.12232851454608107, 'min_child_weight': 4, 'lambda': 8.729693795466556, 'n_estimators': 725, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:29,993] Trial 106 finished with value: 0.8434111759799834 and parameters: {'learning_rate': 0.14240875132759095, 'min_child_weight': 4, 'lambda': 8.076900681351768, 'n_estimators': 839, 'max_depth': 2}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:32,362] Trial 107 finished with value: 0.8334278565471227 and parameters: {'learning_rate': 0.13890024750720037, 'min_child_weight': 4, 'lambda': 8.106384597805814, 'n_estimators': 719, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:34,478] Trial 108 finished with value: 0.8325271059216013 and parameters: {'learning_rate': 0.13997759973236268, 'min_child_weight': 4, 'lambda': 8.149243492018018, 'n_estimators': 765, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:36,462] Trial 109 finished with value: 0.8352710592160133 and parameters: {'learning_rate': 0.13491345858033582, 'min_child_weight': 3, 'lambda': 8.098792090116858, 'n_estimators': 804, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:37,477] Trial 111 finished with value: 0.8433944954128441 and parameters: {'learning_rate': 0.1385509725323363, 'min_child_weight': 3, 'lambda': 8.253642196970555, 'n_estimators': 104, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:38,602] Trial 110 finished with value: 0.8343369474562137 and parameters: {'learning_rate': 0.14152598577485329, 'min_child_weight': 3, 'lambda': 8.120298919337309, 'n_estimators': 728, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:40,377] Trial 112 finished with value: 0.8379733110925771 and parameters: {'learning_rate': 0.10871447636149935, 'min_child_weight': 3, 'lambda': 8.161163787738307, 'n_estimators': 829, 'max_depth': 8}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:40,821] Trial 114 finished with value: 0.8434111759799834 and parameters: {'learning_rate': 0.10559724506106308, 'min_child_weight': 3, 'lambda': 8.147713371863343, 'n_estimators': 238, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:42,131] Trial 113 finished with value: 0.8397831526271894 and parameters: {'learning_rate': 0.10542224443649671, 'min_child_weight': 3, 'lambda': 8.247836487018278, 'n_estimators': 817, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:42,160] Trial 115 finished with value: 0.8388573811509591 and parameters: {'learning_rate': 0.10678601859337505, 'min_child_weight': 3, 'lambda': 8.188345003434762, 'n_estimators': 204, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:42,654] Trial 116 finished with value: 0.8434111759799834 and parameters: {'learning_rate': 0.10668368424539104, 'min_child_weight': 3, 'lambda': 7.8171374169777845, 'n_estimators': 252, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:43,160] Trial 117 finished with value: 0.8461384487072561 and parameters: {'learning_rate': 0.11166193617497402, 'min_child_weight': 3, 'lambda': 7.847948473380528, 'n_estimators': 198, 'max_depth': 7}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:45,018] Trial 118 finished with value: 0.83976647206005 and parameters: {'learning_rate': 0.09785529957723245, 'min_child_weight': 3, 'lambda': 7.9511407411541875, 'n_estimators': 861, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:46,884] Trial 119 finished with value: 0.8352710592160134 and parameters: {'learning_rate': 0.20022824178165208, 'min_child_weight': 3, 'lambda': 7.878034062931316, 'n_estimators': 926, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:47,868] Trial 120 finished with value: 0.8397748123436198 and parameters: {'learning_rate': 0.10018220811866063, 'min_child_weight': 3, 'lambda': 7.925361194523766, 'n_estimators': 811, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:49,418] Trial 121 finished with value: 0.8343369474562135 and parameters: {'learning_rate': 0.20577879680255864, 'min_child_weight': 3, 'lambda': 7.263364022804946, 'n_estimators': 953, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:50,449] Trial 123 finished with value: 0.8397831526271894 and parameters: {'learning_rate': 0.1022606680654169, 'min_child_weight': 3, 'lambda': 7.885946139893215, 'n_estimators': 193, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:51,022] Trial 122 finished with value: 0.8443286071726439 and parameters: {'learning_rate': 0.09857408803914258, 'min_child_weight': 3, 'lambda': 7.81421200342768, 'n_estimators': 981, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:51,759] Trial 125 finished with value: 0.8452210175145953 and parameters: {'learning_rate': 0.21326980971430431, 'min_child_weight': 3, 'lambda': 7.8276171880519, 'n_estimators': 191, 'max_depth': 4}. Best is trial 41 with value: 0.8461384487072561.\n",
            "[I 2023-06-10 13:37:51,992] Trial 124 finished with value: 0.8479649708090076 and parameters: {'learning_rate': 0.09449045587950514, 'min_child_weight': 3, 'lambda': 7.8643156724555725, 'n_estimators': 306, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:54,583] Trial 126 finished with value: 0.8270892410341952 and parameters: {'learning_rate': 0.22091015532859598, 'min_child_weight': 3, 'lambda': 8.600314252315815, 'n_estimators': 993, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:55,133] Trial 128 finished with value: 0.833394495412844 and parameters: {'learning_rate': 0.217514891459226, 'min_child_weight': 3, 'lambda': 7.929851970819978, 'n_estimators': 263, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:55,575] Trial 129 finished with value: 0.8324937447873229 and parameters: {'learning_rate': 0.213780321769234, 'min_child_weight': 3, 'lambda': 7.7882608207649175, 'n_estimators': 255, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:55,674] Trial 127 finished with value: 0.8443452877397831 and parameters: {'learning_rate': 0.21264305708145087, 'min_child_weight': 3, 'lambda': 7.870478935047981, 'n_estimators': 1011, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:56,450] Trial 130 finished with value: 0.8334111759799834 and parameters: {'learning_rate': 0.1953503572317023, 'min_child_weight': 3, 'lambda': 7.886496870570971, 'n_estimators': 309, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:57,299] Trial 131 finished with value: 0.8370391993327772 and parameters: {'learning_rate': 0.2147447779243089, 'min_child_weight': 3, 'lambda': 7.832851569483435, 'n_estimators': 307, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:58,342] Trial 132 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.052547949788758555, 'min_child_weight': 3, 'lambda': 7.194456856857842, 'n_estimators': 307, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:59,060] Trial 133 finished with value: 0.8443119266055046 and parameters: {'learning_rate': 0.05522379658596575, 'min_child_weight': 3, 'lambda': 7.758598793285205, 'n_estimators': 303, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:37:59,881] Trial 134 finished with value: 0.8425104253544621 and parameters: {'learning_rate': 0.1559231602676135, 'min_child_weight': 3, 'lambda': 8.601019277620424, 'n_estimators': 281, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:00,870] Trial 135 finished with value: 0.8415763135946623 and parameters: {'learning_rate': 0.053256888171927044, 'min_child_weight': 3, 'lambda': 8.605883479999523, 'n_estimators': 294, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:01,558] Trial 136 finished with value: 0.8433944954128441 and parameters: {'learning_rate': 0.05613400118929204, 'min_child_weight': 3, 'lambda': 8.590275565282093, 'n_estimators': 309, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:02,224] Trial 137 finished with value: 0.8361301084236864 and parameters: {'learning_rate': 0.15678598186431172, 'min_child_weight': 3, 'lambda': 7.3671290697069844, 'n_estimators': 292, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:02,724] Trial 138 finished with value: 0.8406672226855714 and parameters: {'learning_rate': 0.05466466194680347, 'min_child_weight': 3, 'lambda': 7.335588707495327, 'n_estimators': 287, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:05,840] Trial 139 finished with value: 0.8388573811509593 and parameters: {'learning_rate': 0.058484062818211016, 'min_child_weight': 3, 'lambda': 7.373130210547024, 'n_estimators': 1063, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:06,356] Trial 140 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.05902772223147428, 'min_child_weight': 3, 'lambda': 7.303296333658959, 'n_estimators': 315, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:09,787] Trial 141 finished with value: 0.8361384487072561 and parameters: {'learning_rate': 0.05606625738142338, 'min_child_weight': 3, 'lambda': 7.342527761559083, 'n_estimators': 1172, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:12,589] Trial 142 finished with value: 0.8416096747289409 and parameters: {'learning_rate': 0.0540647309575657, 'min_child_weight': 3, 'lambda': 7.408102248640278, 'n_estimators': 1043, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:14,983] Trial 144 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.16169558286941096, 'min_child_weight': 3, 'lambda': 7.467088929236835, 'n_estimators': 907, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:15,191] Trial 143 finished with value: 0.83976647206005 and parameters: {'learning_rate': 0.05461332988105029, 'min_child_weight': 3, 'lambda': 7.338570035195146, 'n_estimators': 1032, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:18,221] Trial 146 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.05839006841324846, 'min_child_weight': 3, 'lambda': 7.50897581341067, 'n_estimators': 208, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:18,611] Trial 145 finished with value: 0.8316430358632193 and parameters: {'learning_rate': 0.16146731388453686, 'min_child_weight': 3, 'lambda': 7.360430782095946, 'n_estimators': 1086, 'max_depth': 7}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:20,987] Trial 147 finished with value: 0.8407089241034195 and parameters: {'learning_rate': 0.05991206704733043, 'min_child_weight': 3, 'lambda': 7.3578536775003425, 'n_estimators': 1163, 'max_depth': 5}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:23,029] Trial 148 finished with value: 0.837047539616347 and parameters: {'learning_rate': 0.08874838740026066, 'min_child_weight': 3, 'lambda': 7.407764569984525, 'n_estimators': 1103, 'max_depth': 5}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:25,438] Trial 149 finished with value: 0.83976647206005 and parameters: {'learning_rate': 0.06005388241031171, 'min_child_weight': 3, 'lambda': 7.4174781154525276, 'n_estimators': 1176, 'max_depth': 5}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:29,554] Trial 150 finished with value: 0.8297914929107589 and parameters: {'learning_rate': 0.09042524883803463, 'min_child_weight': 3, 'lambda': 7.403731154699714, 'n_estimators': 1287, 'max_depth': 12}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:31,769] Trial 151 finished with value: 0.8461384487072561 and parameters: {'learning_rate': 0.02736919749157183, 'min_child_weight': 3, 'lambda': 9.426347444235255, 'n_estimators': 1142, 'max_depth': 5}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:32,361] Trial 152 finished with value: 0.8343202668890741 and parameters: {'learning_rate': 0.09221691614673057, 'min_child_weight': 3, 'lambda': 7.666889204419897, 'n_estimators': 1116, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:33,169] Trial 153 finished with value: 0.8334111759799834 and parameters: {'learning_rate': 0.08949862613142773, 'min_child_weight': 3, 'lambda': 8.349370046709533, 'n_estimators': 1118, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:34,303] Trial 154 finished with value: 0.843419516263553 and parameters: {'learning_rate': 0.1211095932130789, 'min_child_weight': 5, 'lambda': 8.340263854701627, 'n_estimators': 1110, 'max_depth': 2}. Best is trial 124 with value: 0.8479649708090076.\n",
            "[I 2023-06-10 13:38:36,121] Trial 156 finished with value: 0.8479816513761469 and parameters: {'learning_rate': 0.12268261448301783, 'min_child_weight': 5, 'lambda': 8.399910711080418, 'n_estimators': 198, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:36,553] Trial 155 finished with value: 0.8370809007506255 and parameters: {'learning_rate': 0.09451406141602875, 'min_child_weight': 5, 'lambda': 8.338032527175065, 'n_estimators': 1115, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:38,773] Trial 158 finished with value: 0.8379566305254379 and parameters: {'learning_rate': 0.08701272566343979, 'min_child_weight': 5, 'lambda': 7.654863203353787, 'n_estimators': 177, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:39,789] Trial 157 finished with value: 0.8334528773978315 and parameters: {'learning_rate': 0.08899126905006416, 'min_child_weight': 5, 'lambda': 8.321059093264289, 'n_estimators': 1107, 'max_depth': 12}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:40,676] Trial 160 finished with value: 0.8297581317764804 and parameters: {'learning_rate': 0.12417543672062491, 'min_child_weight': 5, 'lambda': 8.39691887289126, 'n_estimators': 214, 'max_depth': 2}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:41,160] Trial 159 finished with value: 0.8434445371142619 and parameters: {'learning_rate': 0.12093692161909884, 'min_child_weight': 5, 'lambda': 8.347473815995935, 'n_estimators': 409, 'max_depth': 12}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:43,684] Trial 161 finished with value: 0.8343536280233528 and parameters: {'learning_rate': 0.12030072451920278, 'min_child_weight': 5, 'lambda': 8.401480695393612, 'n_estimators': 957, 'max_depth': 12}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:44,267] Trial 162 finished with value: 0.8388657214345289 and parameters: {'learning_rate': 0.12636119557705197, 'min_child_weight': 1, 'lambda': 8.345381444882669, 'n_estimators': 228, 'max_depth': 17}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:44,600] Trial 163 finished with value: 0.846163469557965 and parameters: {'learning_rate': 0.12091267313595694, 'min_child_weight': 5, 'lambda': 8.324605880318371, 'n_estimators': 182, 'max_depth': 17}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:44,794] Trial 164 finished with value: 0.8370391993327774 and parameters: {'learning_rate': 0.11867298408113591, 'min_child_weight': 1, 'lambda': 9.609020816554533, 'n_estimators': 123, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:45,309] Trial 166 finished with value: 0.8297247706422018 and parameters: {'learning_rate': 0.032323175776283145, 'min_child_weight': 5, 'lambda': 9.583554357885978, 'n_estimators': 58, 'max_depth': 15}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:45,317] Trial 165 finished with value: 0.8352126772310259 and parameters: {'learning_rate': 0.12661121743802753, 'min_child_weight': 1, 'lambda': 9.445326805457812, 'n_estimators': 126, 'max_depth': 15}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:45,653] Trial 167 finished with value: 0.8406839032527106 and parameters: {'learning_rate': 0.12389229117652052, 'min_child_weight': 5, 'lambda': 9.525537567892943, 'n_estimators': 123, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:46,078] Trial 168 finished with value: 0.8315679733110926 and parameters: {'learning_rate': 0.024453447347475777, 'min_child_weight': 5, 'lambda': 9.275822974545795, 'n_estimators': 182, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:46,341] Trial 169 finished with value: 0.8434195162635529 and parameters: {'learning_rate': 0.12317222278049283, 'min_child_weight': 5, 'lambda': 9.444669553356665, 'n_estimators': 122, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:46,967] Trial 170 finished with value: 0.8397748123436196 and parameters: {'learning_rate': 0.02857478105499872, 'min_child_weight': 1, 'lambda': 9.46318584731593, 'n_estimators': 219, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:48,874] Trial 172 finished with value: 0.8397748123436196 and parameters: {'learning_rate': 0.12198450144876229, 'min_child_weight': 5, 'lambda': 9.550328599923834, 'n_estimators': 116, 'max_depth': 15}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:50,099] Trial 171 finished with value: 0.8334528773978317 and parameters: {'learning_rate': 0.11921471056221734, 'min_child_weight': 5, 'lambda': 9.312529705346213, 'n_estimators': 1237, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:50,433] Trial 173 finished with value: 0.8297497914929106 and parameters: {'learning_rate': 0.028548482035339398, 'min_child_weight': 5, 'lambda': 9.527244767826657, 'n_estimators': 185, 'max_depth': 13}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:50,595] Trial 175 finished with value: 0.828815679733111 and parameters: {'learning_rate': 0.029582000525322907, 'min_child_weight': 5, 'lambda': 9.553077321593541, 'n_estimators': 49, 'max_depth': 19}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:50,595] Trial 174 finished with value: 0.8306588824020018 and parameters: {'learning_rate': 0.032983775170838926, 'min_child_weight': 5, 'lambda': 9.482079783089123, 'n_estimators': 124, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:50,827] Trial 176 finished with value: 0.8306338615512928 and parameters: {'learning_rate': 0.026166933562403294, 'min_child_weight': 5, 'lambda': 8.689454474992193, 'n_estimators': 58, 'max_depth': 16}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:52,141] Trial 178 finished with value: 0.8370809007506255 and parameters: {'learning_rate': 0.1840272611621852, 'min_child_weight': 5, 'lambda': 8.557716442643706, 'n_estimators': 408, 'max_depth': 19}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:52,524] Trial 177 finished with value: 0.8306588824020018 and parameters: {'learning_rate': 0.0255994028097821, 'min_child_weight': 5, 'lambda': 9.454178726988687, 'n_estimators': 181, 'max_depth': 14}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:53,116] Trial 179 finished with value: 0.834303586321935 and parameters: {'learning_rate': 0.025276508434067896, 'min_child_weight': 5, 'lambda': 8.556352406065566, 'n_estimators': 196, 'max_depth': 19}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:53,782] Trial 180 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.18412129701072044, 'min_child_weight': 3, 'lambda': 7.978391862244224, 'n_estimators': 186, 'max_depth': 18}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:54,382] Trial 181 finished with value: 0.8434278565471226 and parameters: {'learning_rate': 0.1824237826705398, 'min_child_weight': 3, 'lambda': 8.61745117889797, 'n_estimators': 416, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:58,522] Trial 183 finished with value: 0.8379899916597164 and parameters: {'learning_rate': 0.1925098145407242, 'min_child_weight': 5, 'lambda': 8.617541699266209, 'n_estimators': 414, 'max_depth': 18}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:58,602] Trial 182 finished with value: 0.8352710592160133 and parameters: {'learning_rate': 0.1871856440154033, 'min_child_weight': 5, 'lambda': 8.643089988030795, 'n_estimators': 1239, 'max_depth': 14}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:38:59,994] Trial 184 finished with value: 0.8416346955796495 and parameters: {'learning_rate': 0.18730874298060135, 'min_child_weight': 5, 'lambda': 8.634569564603552, 'n_estimators': 415, 'max_depth': 14}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:00,240] Trial 185 finished with value: 0.8407005838198499 and parameters: {'learning_rate': 0.18328024749439809, 'min_child_weight': 5, 'lambda': 8.689432710370683, 'n_estimators': 245, 'max_depth': 16}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:01,647] Trial 186 finished with value: 0.837998331943286 and parameters: {'learning_rate': 0.17766272993102727, 'min_child_weight': 3, 'lambda': 8.628438820956749, 'n_estimators': 403, 'max_depth': 20}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:02,640] Trial 188 finished with value: 0.8443202668890741 and parameters: {'learning_rate': 0.1849223543145794, 'min_child_weight': 3, 'lambda': 7.984122774048345, 'n_estimators': 255, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:03,147] Trial 187 finished with value: 0.8388824020016681 and parameters: {'learning_rate': 0.1820051718508066, 'min_child_weight': 3, 'lambda': 7.934593015024064, 'n_estimators': 404, 'max_depth': 17}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:03,473] Trial 189 finished with value: 0.8416346955796496 and parameters: {'learning_rate': 0.3044147861862198, 'min_child_weight': 3, 'lambda': 8.021681695632424, 'n_estimators': 339, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:03,822] Trial 190 finished with value: 0.8425271059216014 and parameters: {'learning_rate': 0.29111000161291223, 'min_child_weight': 3, 'lambda': 7.980322036265642, 'n_estimators': 339, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:04,331] Trial 191 finished with value: 0.8443536280233527 and parameters: {'learning_rate': 0.29493941273459356, 'min_child_weight': 3, 'lambda': 8.020000179836188, 'n_estimators': 338, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:04,781] Trial 192 finished with value: 0.8470642201834864 and parameters: {'learning_rate': 0.15292432976489698, 'min_child_weight': 3, 'lambda': 7.729363052806498, 'n_estimators': 347, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:05,214] Trial 193 finished with value: 0.8470725604670559 and parameters: {'learning_rate': 0.15358791152231352, 'min_child_weight': 3, 'lambda': 7.992832436616868, 'n_estimators': 339, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:05,505] Trial 194 finished with value: 0.843419516263553 and parameters: {'learning_rate': 0.15318643990084446, 'min_child_weight': 3, 'lambda': 8.044518080056312, 'n_estimators': 248, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:05,839] Trial 195 finished with value: 0.8434111759799834 and parameters: {'learning_rate': 0.2899000886311812, 'min_child_weight': 3, 'lambda': 8.012575833961792, 'n_estimators': 252, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:06,188] Trial 196 finished with value: 0.8406922435362804 and parameters: {'learning_rate': 0.1464885429317144, 'min_child_weight': 3, 'lambda': 7.970441771875698, 'n_estimators': 231, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:07,689] Trial 198 finished with value: 0.8251709758131778 and parameters: {'learning_rate': 0.15172499218260788, 'min_child_weight': 3, 'lambda': 8.220325443194305, 'n_estimators': 337, 'max_depth': 1}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:08,357] Trial 197 finished with value: 0.8388907422852376 and parameters: {'learning_rate': 0.16769205245508023, 'min_child_weight': 3, 'lambda': 8.044698715216807, 'n_estimators': 1408, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:08,581] Trial 199 finished with value: 0.8425020850708924 and parameters: {'learning_rate': 0.2362038245602065, 'min_child_weight': 3, 'lambda': 8.060044213603074, 'n_estimators': 258, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:09,071] Trial 200 finished with value: 0.8425020850708925 and parameters: {'learning_rate': 0.14701974058859177, 'min_child_weight': 3, 'lambda': 8.049476868690626, 'n_estimators': 349, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:09,422] Trial 201 finished with value: 0.8434028356964138 and parameters: {'learning_rate': 0.151954428093133, 'min_child_weight': 3, 'lambda': 7.811284197021377, 'n_estimators': 261, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:09,854] Trial 202 finished with value: 0.8443202668890744 and parameters: {'learning_rate': 0.1494891522160749, 'min_child_weight': 3, 'lambda': 8.281852474986486, 'n_estimators': 265, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:10,197] Trial 203 finished with value: 0.8434195162635529 and parameters: {'learning_rate': 0.24127382951836984, 'min_child_weight': 3, 'lambda': 7.772596947419767, 'n_estimators': 260, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:10,614] Trial 204 finished with value: 0.8452460383653044 and parameters: {'learning_rate': 0.1551667218857147, 'min_child_weight': 3, 'lambda': 8.162912069558253, 'n_estimators': 263, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:10,854] Trial 205 finished with value: 0.8406922435362804 and parameters: {'learning_rate': 0.1541630887905785, 'min_child_weight': 3, 'lambda': 7.740199055058192, 'n_estimators': 276, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:11,197] Trial 206 finished with value: 0.8425020850708925 and parameters: {'learning_rate': 0.14785225985812084, 'min_child_weight': 3, 'lambda': 7.8111457952954755, 'n_estimators': 274, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:11,730] Trial 207 finished with value: 0.8434361968306922 and parameters: {'learning_rate': 0.23350891606035876, 'min_child_weight': 3, 'lambda': 7.728861019601024, 'n_estimators': 359, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:12,271] Trial 208 finished with value: 0.8461551292743954 and parameters: {'learning_rate': 0.16494999046616, 'min_child_weight': 3, 'lambda': 7.76150185536307, 'n_estimators': 349, 'max_depth': 3}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:12,736] Trial 209 finished with value: 0.8443286071726439 and parameters: {'learning_rate': 0.15396085682039068, 'min_child_weight': 3, 'lambda': 7.768199995627326, 'n_estimators': 268, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:13,246] Trial 210 finished with value: 0.8434278565471226 and parameters: {'learning_rate': 0.24833066251718489, 'min_child_weight': 3, 'lambda': 7.822831496189574, 'n_estimators': 272, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:13,854] Trial 211 finished with value: 0.8416013344453711 and parameters: {'learning_rate': 0.23224313172857416, 'min_child_weight': 3, 'lambda': 7.816498696608265, 'n_estimators': 358, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:14,230] Trial 212 finished with value: 0.8452293577981651 and parameters: {'learning_rate': 0.10764854202215302, 'min_child_weight': 3, 'lambda': 7.768384267143506, 'n_estimators': 279, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:14,712] Trial 213 finished with value: 0.8416096747289409 and parameters: {'learning_rate': 0.23698425090982128, 'min_child_weight': 3, 'lambda': 8.302623538347706, 'n_estimators': 277, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:15,087] Trial 214 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.2415271239507912, 'min_child_weight': 3, 'lambda': 7.730753997388432, 'n_estimators': 277, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:15,582] Trial 215 finished with value: 0.8416180150125104 and parameters: {'learning_rate': 0.34588961177630617, 'min_child_weight': 3, 'lambda': 7.744649287647207, 'n_estimators': 282, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:16,071] Trial 216 finished with value: 0.843419516263553 and parameters: {'learning_rate': 0.16113207181156042, 'min_child_weight': 3, 'lambda': 7.695779230632375, 'n_estimators': 278, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:16,604] Trial 217 finished with value: 0.845254378648874 and parameters: {'learning_rate': 0.2225858758898044, 'min_child_weight': 3, 'lambda': 8.253202245268572, 'n_estimators': 317, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:17,160] Trial 218 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.20713959933467854, 'min_child_weight': 3, 'lambda': 8.26206116805939, 'n_estimators': 315, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:17,362] Trial 219 finished with value: 0.8415929941618016 and parameters: {'learning_rate': 0.20870857823797295, 'min_child_weight': 3, 'lambda': 8.21653793994456, 'n_estimators': 208, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:17,770] Trial 220 finished with value: 0.8452460383653044 and parameters: {'learning_rate': 0.20133188096833393, 'min_child_weight': 3, 'lambda': 8.220309556564876, 'n_estimators': 220, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:18,077] Trial 221 finished with value: 0.8470558798999166 and parameters: {'learning_rate': 0.16737465125722048, 'min_child_weight': 3, 'lambda': 8.21957452535253, 'n_estimators': 218, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:18,670] Trial 222 finished with value: 0.8425020850708925 and parameters: {'learning_rate': 0.21242945376087938, 'min_child_weight': 3, 'lambda': 8.210663215867696, 'n_estimators': 320, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:19,053] Trial 223 finished with value: 0.8370308590492078 and parameters: {'learning_rate': 0.16514170234341546, 'min_child_weight': 3, 'lambda': 8.238786402317206, 'n_estimators': 234, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:19,528] Trial 224 finished with value: 0.8434195162635529 and parameters: {'learning_rate': 0.10298887260255123, 'min_child_weight': 3, 'lambda': 8.24515945988763, 'n_estimators': 226, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:19,812] Trial 225 finished with value: 0.8443119266055046 and parameters: {'learning_rate': 0.10707240911194654, 'min_child_weight': 3, 'lambda': 6.084233002428887, 'n_estimators': 220, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:20,161] Trial 226 finished with value: 0.8461301084236863 and parameters: {'learning_rate': 0.1038560200568341, 'min_child_weight': 3, 'lambda': 5.149044805471339, 'n_estimators': 217, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:20,379] Trial 227 finished with value: 0.8279316096747289 and parameters: {'learning_rate': 0.10652571067144956, 'min_child_weight': 3, 'lambda': 8.28678234708848, 'n_estimators': 215, 'max_depth': 2}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:20,703] Trial 228 finished with value: 0.8279399499582984 and parameters: {'learning_rate': 0.10631222805646387, 'min_child_weight': 3, 'lambda': 8.212445294238364, 'n_estimators': 320, 'max_depth': 2}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:21,394] Trial 229 finished with value: 0.8434028356964136 and parameters: {'learning_rate': 0.10804952498959183, 'min_child_weight': 3, 'lambda': 7.007588321423548, 'n_estimators': 322, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:21,820] Trial 230 finished with value: 0.847047539616347 and parameters: {'learning_rate': 0.10038637897547939, 'min_child_weight': 3, 'lambda': 7.045098456165161, 'n_estimators': 224, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:22,345] Trial 231 finished with value: 0.847956630525438 and parameters: {'learning_rate': 0.1042013793078676, 'min_child_weight': 3, 'lambda': 7.052081368936646, 'n_estimators': 229, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:22,777] Trial 232 finished with value: 0.8406839032527106 and parameters: {'learning_rate': 0.10917068089115817, 'min_child_weight': 3, 'lambda': 4.879243380854444, 'n_estimators': 213, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:23,061] Trial 233 finished with value: 0.8461384487072561 and parameters: {'learning_rate': 0.10440937757975219, 'min_child_weight': 3, 'lambda': 7.001931100626754, 'n_estimators': 158, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:23,327] Trial 234 finished with value: 0.840675562969141 and parameters: {'learning_rate': 0.11022234541449635, 'min_child_weight': 3, 'lambda': 4.799343762325343, 'n_estimators': 219, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:23,786] Trial 235 finished with value: 0.837047539616347 and parameters: {'learning_rate': 0.4696467069626222, 'min_child_weight': 3, 'lambda': 8.45395447572065, 'n_estimators': 214, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:24,295] Trial 236 finished with value: 0.8443202668890744 and parameters: {'learning_rate': 0.11080997956426014, 'min_child_weight': 3, 'lambda': 8.971879664752809, 'n_estimators': 215, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:24,595] Trial 237 finished with value: 0.8434028356964138 and parameters: {'learning_rate': 0.12872473680520177, 'min_child_weight': 3, 'lambda': 5.098893030047922, 'n_estimators': 161, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:24,971] Trial 238 finished with value: 0.8452543786488741 and parameters: {'learning_rate': 0.4382823789909468, 'min_child_weight': 3, 'lambda': 7.5611479736228215, 'n_estimators': 159, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:25,194] Trial 239 finished with value: 0.8452293577981651 and parameters: {'learning_rate': 0.13869047073446628, 'min_child_weight': 3, 'lambda': 4.260405728815943, 'n_estimators': 161, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:25,451] Trial 240 finished with value: 0.8452210175145956 and parameters: {'learning_rate': 0.1343619335093179, 'min_child_weight': 3, 'lambda': 5.961999222314195, 'n_estimators': 162, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:25,794] Trial 241 finished with value: 0.8434028356964138 and parameters: {'learning_rate': 0.13360893878822955, 'min_child_weight': 3, 'lambda': 5.522650414375143, 'n_estimators': 172, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:26,199] Trial 242 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.13268586480639835, 'min_child_weight': 3, 'lambda': 5.359210399993821, 'n_estimators': 171, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:26,552] Trial 243 finished with value: 0.8388573811509591 and parameters: {'learning_rate': 0.07287157542324466, 'min_child_weight': 3, 'lambda': 6.786272920263838, 'n_estimators': 161, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:26,943] Trial 244 finished with value: 0.8415763135946621 and parameters: {'learning_rate': 0.07757748980845994, 'min_child_weight': 3, 'lambda': 6.759774180989492, 'n_estimators': 160, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:27,079] Trial 245 finished with value: 0.8416180150125104 and parameters: {'learning_rate': 0.448992683104921, 'min_child_weight': 3, 'lambda': 6.555871993591809, 'n_estimators': 152, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:27,431] Trial 246 finished with value: 0.844303586321935 and parameters: {'learning_rate': 0.133497171381516, 'min_child_weight': 3, 'lambda': 7.087212542735158, 'n_estimators': 162, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:27,835] Trial 247 finished with value: 0.8461217681401166 and parameters: {'learning_rate': 0.13700622945636842, 'min_child_weight': 3, 'lambda': 6.709492967471486, 'n_estimators': 165, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:28,161] Trial 248 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.08439135263003708, 'min_child_weight': 3, 'lambda': 6.91992260560183, 'n_estimators': 151, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:28,502] Trial 249 finished with value: 0.8406839032527106 and parameters: {'learning_rate': 0.07665914511830732, 'min_child_weight': 3, 'lambda': 6.916529005580688, 'n_estimators': 174, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:28,861] Trial 250 finished with value: 0.847047539616347 and parameters: {'learning_rate': 0.07969663266106, 'min_child_weight': 3, 'lambda': 7.099048399076858, 'n_estimators': 160, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:29,144] Trial 251 finished with value: 0.8415763135946621 and parameters: {'learning_rate': 0.08320114545690051, 'min_child_weight': 3, 'lambda': 6.81488146844109, 'n_estimators': 159, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:29,418] Trial 252 finished with value: 0.836163469557965 and parameters: {'learning_rate': 0.5656730570456178, 'min_child_weight': 3, 'lambda': 6.782521743520375, 'n_estimators': 154, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:29,718] Trial 253 finished with value: 0.8415763135946623 and parameters: {'learning_rate': 0.07661173368749052, 'min_child_weight': 3, 'lambda': 6.4360351920098795, 'n_estimators': 150, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:30,001] Trial 254 finished with value: 0.8397581317764805 and parameters: {'learning_rate': 0.07146142133516944, 'min_child_weight': 3, 'lambda': 7.060241084236533, 'n_estimators': 141, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:30,352] Trial 255 finished with value: 0.8388573811509591 and parameters: {'learning_rate': 0.08232451892086141, 'min_child_weight': 3, 'lambda': 4.3914285244760976, 'n_estimators': 146, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:30,652] Trial 256 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.08118692037329225, 'min_child_weight': 3, 'lambda': 4.4223308026315165, 'n_estimators': 150, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:31,002] Trial 257 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.13582601882579165, 'min_child_weight': 3, 'lambda': 7.158226979291039, 'n_estimators': 184, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:31,344] Trial 258 finished with value: 0.8443119266055046 and parameters: {'learning_rate': 0.0892767998712382, 'min_child_weight': 3, 'lambda': 7.1080543642741425, 'n_estimators': 193, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:31,501] Trial 259 finished with value: 0.8407005838198499 and parameters: {'learning_rate': 0.5486194404313814, 'min_child_weight': 3, 'lambda': 7.108050412821015, 'n_estimators': 93, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:31,960] Trial 260 finished with value: 0.8343619683069223 and parameters: {'learning_rate': 0.5320569605132252, 'min_child_weight': 3, 'lambda': 4.325343310961506, 'n_estimators': 184, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:32,460] Trial 261 finished with value: 0.8334195162635529 and parameters: {'learning_rate': 0.5563871092452702, 'min_child_weight': 3, 'lambda': 6.270780687715169, 'n_estimators': 192, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:32,634] Trial 262 finished with value: 0.8379816513761467 and parameters: {'learning_rate': 0.40830635555452377, 'min_child_weight': 3, 'lambda': 4.510697983497658, 'n_estimators': 131, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:33,101] Trial 263 finished with value: 0.8307089241034195 and parameters: {'learning_rate': 0.6332564554746029, 'min_child_weight': 3, 'lambda': 4.3961160043116, 'n_estimators': 190, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:33,213] Trial 264 finished with value: 0.8379482902418683 and parameters: {'learning_rate': 0.13803782367175266, 'min_child_weight': 3, 'lambda': 7.103640998434455, 'n_estimators': 79, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:33,438] Trial 265 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.32393764409414383, 'min_child_weight': 3, 'lambda': 7.106927926110232, 'n_estimators': 95, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:33,934] Trial 266 finished with value: 0.840675562969141 and parameters: {'learning_rate': 0.13679805736131923, 'min_child_weight': 3, 'lambda': 4.182422637626199, 'n_estimators': 191, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:34,136] Trial 267 finished with value: 0.847047539616347 and parameters: {'learning_rate': 0.16950684224875098, 'min_child_weight': 3, 'lambda': 5.980693015355679, 'n_estimators': 84, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:34,352] Trial 268 finished with value: 0.8443119266055046 and parameters: {'learning_rate': 0.13922455427036456, 'min_child_weight': 3, 'lambda': 7.5366502311154004, 'n_estimators': 94, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:34,810] Trial 269 finished with value: 0.847047539616347 and parameters: {'learning_rate': 0.16757796962224072, 'min_child_weight': 3, 'lambda': 7.128861191583878, 'n_estimators': 200, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:34,984] Trial 270 finished with value: 0.8443536280233529 and parameters: {'learning_rate': 0.38242107344597737, 'min_child_weight': 3, 'lambda': 7.531698615667384, 'n_estimators': 85, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:35,501] Trial 271 finished with value: 0.8425187656380316 and parameters: {'learning_rate': 0.17290321204180087, 'min_child_weight': 3, 'lambda': 4.217860120962072, 'n_estimators': 193, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:35,651] Trial 272 finished with value: 0.8424854045037533 and parameters: {'learning_rate': 0.16373178918450335, 'min_child_weight': 3, 'lambda': 6.394639120329108, 'n_estimators': 99, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:35,996] Trial 273 finished with value: 0.8424937447873229 and parameters: {'learning_rate': 0.16605507835853925, 'min_child_weight': 3, 'lambda': 7.540457480278688, 'n_estimators': 122, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:36,644] Trial 274 finished with value: 0.8461467889908256 and parameters: {'learning_rate': 0.15874629235821236, 'min_child_weight': 3, 'lambda': 6.5856244646713815, 'n_estimators': 242, 'max_depth': 6}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:36,967] Trial 275 finished with value: 0.840675562969141 and parameters: {'learning_rate': 0.16947420769423233, 'min_child_weight': 3, 'lambda': 6.56904157360749, 'n_estimators': 228, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:37,093] Trial 276 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.1537534329547157, 'min_child_weight': 3, 'lambda': 5.8738339250628595, 'n_estimators': 102, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:37,546] Trial 277 finished with value: 0.8461384487072561 and parameters: {'learning_rate': 0.17001806257445243, 'min_child_weight': 3, 'lambda': 6.641744130238391, 'n_estimators': 233, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:37,983] Trial 278 finished with value: 0.8452210175145956 and parameters: {'learning_rate': 0.16326787003429571, 'min_child_weight': 3, 'lambda': 7.51048203022802, 'n_estimators': 244, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:38,340] Trial 279 finished with value: 0.8461467889908256 and parameters: {'learning_rate': 0.16805905378467131, 'min_child_weight': 3, 'lambda': 6.424234303874216, 'n_estimators': 239, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:38,801] Trial 280 finished with value: 0.8470475396163468 and parameters: {'learning_rate': 0.16773370815776545, 'min_child_weight': 3, 'lambda': 6.467353889068425, 'n_estimators': 232, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:38,917] Trial 282 finished with value: 0.8306588824020016 and parameters: {'learning_rate': 0.17519352179126327, 'min_child_weight': 3, 'lambda': 6.839483636640602, 'n_estimators': 12, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:39,308] Trial 281 finished with value: 0.8443286071726439 and parameters: {'learning_rate': 0.16829839945331126, 'min_child_weight': 3, 'lambda': 7.522140158208847, 'n_estimators': 232, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:39,725] Trial 283 finished with value: 0.8479566305254378 and parameters: {'learning_rate': 0.16813610931127188, 'min_child_weight': 3, 'lambda': 6.458860106062175, 'n_estimators': 241, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:40,088] Trial 284 finished with value: 0.8288907422852377 and parameters: {'learning_rate': 0.7067532331462073, 'min_child_weight': 3, 'lambda': 9.982457022919766, 'n_estimators': 240, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:40,625] Trial 285 finished with value: 0.8416263552960801 and parameters: {'learning_rate': 0.36613110893264567, 'min_child_weight': 3, 'lambda': 5.647954003219372, 'n_estimators': 241, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:41,042] Trial 286 finished with value: 0.8461301084236863 and parameters: {'learning_rate': 0.16602256786909203, 'min_child_weight': 3, 'lambda': 6.696330641408541, 'n_estimators': 238, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:41,400] Trial 287 finished with value: 0.8334528773978315 and parameters: {'learning_rate': 0.7174107030969252, 'min_child_weight': 3, 'lambda': 6.694861796335624, 'n_estimators': 242, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:41,638] Trial 289 finished with value: 0.8188240200166806 and parameters: {'learning_rate': 0.19881664475547375, 'min_child_weight': 3, 'lambda': 6.260858104051795, 'n_estimators': 26, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:41,942] Trial 288 finished with value: 0.8461467889908256 and parameters: {'learning_rate': 0.1893565986246381, 'min_child_weight': 3, 'lambda': 6.75361957603991, 'n_estimators': 244, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:42,121] Trial 291 finished with value: 0.8233861551292744 and parameters: {'learning_rate': 0.20075103292675667, 'min_child_weight': 3, 'lambda': 6.646659428167104, 'n_estimators': 12, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:42,282] Trial 290 finished with value: 0.8452376980817349 and parameters: {'learning_rate': 0.196444994534831, 'min_child_weight': 3, 'lambda': 6.646290466667192, 'n_estimators': 232, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:42,729] Trial 292 finished with value: 0.8443119266055046 and parameters: {'learning_rate': 0.1796857432302872, 'min_child_weight': 3, 'lambda': 6.641503028122323, 'n_estimators': 246, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:43,136] Trial 293 finished with value: 0.8470558798999166 and parameters: {'learning_rate': 0.19703510419860742, 'min_child_weight': 3, 'lambda': 6.6198540606415675, 'n_estimators': 231, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:43,587] Trial 294 finished with value: 0.8415846538782319 and parameters: {'learning_rate': 0.19387087163536884, 'min_child_weight': 3, 'lambda': 6.6268130050831395, 'n_estimators': 247, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:44,061] Trial 295 finished with value: 0.8434195162635529 and parameters: {'learning_rate': 0.1859308145164251, 'min_child_weight': 3, 'lambda': 6.54486039336084, 'n_estimators': 243, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:44,449] Trial 296 finished with value: 0.8425104253544621 and parameters: {'learning_rate': 0.19637920714773544, 'min_child_weight': 3, 'lambda': 6.68678859507635, 'n_estimators': 232, 'max_depth': 4}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:45,158] Trial 297 finished with value: 0.8334195162635529 and parameters: {'learning_rate': 0.20211985778364586, 'min_child_weight': 3, 'lambda': 6.610985814255547, 'n_estimators': 210, 'max_depth': 10}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:45,441] Trial 298 finished with value: 0.8415929941618016 and parameters: {'learning_rate': 0.18343456039354494, 'min_child_weight': 2, 'lambda': 6.671546249766955, 'n_estimators': 207, 'max_depth': 5}. Best is trial 156 with value: 0.8479816513761469.\n",
            "[I 2023-06-10 13:39:46,025] Trial 299 finished with value: 0.8379733110925771 and parameters: {'learning_rate': 0.1931137945576453, 'min_child_weight': 3, 'lambda': 6.305966528034164, 'n_estimators': 202, 'max_depth': 11}. Best is trial 156 with value: 0.8479816513761469.\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'learning_rate':trial.suggest_float('learning_rate',0.001,1),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "        'lambda': trial.suggest_float('lambda', 0.01, 10),\n",
        "        \"n_estimators\" : trial.suggest_int('n_estimators', 10, 1500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 20)\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**param)\n",
        "    # return model.score(X_test, y_test)\n",
        "    return  cross_val_score(model, X, y, scoring = 'accuracy', cv=10, n_jobs=-1).mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize',sampler=TPESampler())\n",
        "study.optimize(lambda trial : objective(trial),n_trials=300, n_jobs=-1)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 665,
      "metadata": {
        "id": "L4Zp4aOtT0gi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8479816513761469\n"
          ]
        }
      ],
      "source": [
        "print(study.best_value)\n",
        "params = study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 666,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.8398132004981319"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 667,
      "metadata": {
        "id": "LzahSq3xS30b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.12268261448301783,\n",
              " 'min_child_weight': 5,\n",
              " 'lambda': 8.399910711080418,\n",
              " 'n_estimators': 198,\n",
              " 'max_depth': 5}"
            ]
          },
          "execution_count": 667,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 668,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>SibSp_0</th>\n",
              "      <th>SibSp_1</th>\n",
              "      <th>SibSp_2</th>\n",
              "      <th>Parch_0</th>\n",
              "      <th>Parch_1</th>\n",
              "      <th>Parch_2</th>\n",
              "      <th>...</th>\n",
              "      <th>Frequency_Ticket_4</th>\n",
              "      <th>Frequency_Ticket_7</th>\n",
              "      <th>Family_size_1</th>\n",
              "      <th>Family_size_2</th>\n",
              "      <th>Family_size_3</th>\n",
              "      <th>Family_size_4</th>\n",
              "      <th>Family_size_5</th>\n",
              "      <th>Family_size_7</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.534891</td>\n",
              "      <td>-0.569851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.668392</td>\n",
              "      <td>0.987385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.234070</td>\n",
              "      <td>-0.553435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442776</td>\n",
              "      <td>0.545182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442776</td>\n",
              "      <td>-0.550395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.564327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.435673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.007013</td>\n",
              "      <td>-0.277819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.730039</td>\n",
              "      <td>0.269961</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.730039</td>\n",
              "      <td>0.269961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.686664</td>\n",
              "      <td>0.975874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.624528</td>\n",
              "      <td>-0.100491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.450613</td>\n",
              "      <td>1.121133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.251320</td>\n",
              "      <td>1.022700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1098 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Pclass_1  Pclass_2  Pclass_3  Sex_female   SibSp_0   SibSp_1   SibSp_2  \\\n",
              "0          0.0       0.0       1.0         0.0  0.000000  1.000000  0.000000   \n",
              "1          1.0       0.0       0.0         1.0  0.000000  1.000000  0.000000   \n",
              "2          0.0       0.0       1.0         1.0  1.000000  0.000000  0.000000   \n",
              "3          1.0       0.0       0.0         1.0  0.000000  1.000000  0.000000   \n",
              "4          0.0       0.0       1.0         0.0  1.000000  0.000000  0.000000   \n",
              "...        ...       ...       ...         ...       ...       ...       ...   \n",
              "1093       0.0       0.0       1.0         1.0  0.564327  0.000000  0.435673   \n",
              "1094       1.0       0.0       0.0         1.0  0.000000  0.730039  0.269961   \n",
              "1095       1.0       0.0       0.0         0.0  1.000000  0.000000  0.000000   \n",
              "1096       1.0       0.0       0.0         1.0  0.000000  1.000000  0.000000   \n",
              "1097       1.0       0.0       0.0         1.0  0.000000  1.000000  0.000000   \n",
              "\n",
              "      Parch_0   Parch_1  Parch_2  ...  Frequency_Ticket_4  Frequency_Ticket_7  \\\n",
              "0         1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "1         1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "2         1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "3         1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "4         1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "...       ...       ...      ...  ...                 ...                 ...   \n",
              "1093      0.0  0.435673      0.0  ...                 1.0                 0.0   \n",
              "1094      1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "1095      1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "1096      1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "1097      1.0  0.000000      0.0  ...                 0.0                 0.0   \n",
              "\n",
              "      Family_size_1  Family_size_2  Family_size_3  Family_size_4  \\\n",
              "0               0.0       1.000000       0.000000            0.0   \n",
              "1               0.0       1.000000       0.000000            0.0   \n",
              "2               1.0       0.000000       0.000000            0.0   \n",
              "3               0.0       1.000000       0.000000            0.0   \n",
              "4               1.0       0.000000       0.000000            0.0   \n",
              "...             ...            ...            ...            ...   \n",
              "1093            0.0       0.000000       0.000000            1.0   \n",
              "1094            0.0       0.730039       0.269961            0.0   \n",
              "1095            1.0       0.000000       0.000000            0.0   \n",
              "1096            0.0       1.000000       0.000000            0.0   \n",
              "1097            0.0       1.000000       0.000000            0.0   \n",
              "\n",
              "      Family_size_5  Family_size_7       Age      Fare  \n",
              "0               0.0            0.0 -0.534891 -0.569851  \n",
              "1               0.0            0.0  0.668392  0.987385  \n",
              "2               0.0            0.0 -0.234070 -0.553435  \n",
              "3               0.0            0.0  0.442776  0.545182  \n",
              "4               0.0            0.0  0.442776 -0.550395  \n",
              "...             ...            ...       ...       ...  \n",
              "1093            0.0            0.0 -1.007013 -0.277819  \n",
              "1094            0.0            0.0  1.686664  0.975874  \n",
              "1095            0.0            0.0  1.624528 -0.100491  \n",
              "1096            0.0            0.0  2.450613  1.121133  \n",
              "1097            0.0            0.0  2.251320  1.022700  \n",
              "\n",
              "[1098 rows x 37 columns]"
            ]
          },
          "execution_count": 668,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# {'learning_rate': 0.12268261448301783,\n",
        "#  'min_child_weight': 5,\n",
        "#  'lambda': 8.399910711080418,\n",
        "#  'n_estimators': 198,\n",
        "#  'max_depth': 5}\n",
        "\n",
        "# 0.8479816513761469"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4dPcSdIBS3j2"
      },
      "outputs": [],
      "source": [
        "# def pipeline(data, params, cat_columns, num_columns):\n",
        "\n",
        "#     set_age(data)\n",
        "#     set_cabine(data)\n",
        "#     set_title(data)\n",
        "#     set_fem_size(data)\n",
        "#     data = set_fr_tic(data)\n",
        "\n",
        "#     encode(data, cat_columns, num_columns)\n",
        "\n",
        "#     scaler = StandardScaler()\n",
        "#     data[num_columns] = scaler.fit_transform(data[num_columns])\n",
        "\n",
        "#     data = data.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\n",
        "\n",
        "#     cat = CatBoostClassifier(silent=True, **params, random_strength=1, cat_features=cat_columns)\n",
        "\n",
        "#     print(cross_val_score(cat, X_train, y_train, scoring = 'accuracy', cv=5).mean())\n",
        "\n",
        "#     cat.fit(X_train, y_train)\n",
        "#     predict = cat.predict(data)\n",
        "\n",
        "#     return predict\n",
        "\n",
        "# predict = pipeline(test, params, cat_columns, num_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "WHYV2CA6WRQ_"
      },
      "outputs": [],
      "source": [
        "# 0.8383795309168443"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1o7V1MM0qOqE"
      },
      "outputs": [],
      "source": [
        "# output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predict})\n",
        "# output.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8334039020340389\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Feature shape mismatch, expected: 59, got 13",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[66], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     predict \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(data)\n\u001b[0;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m predict\n\u001b[1;32m---> 29\u001b[0m predict \u001b[39m=\u001b[39m pipeline(test, params, cat_columns, num_columns)\n",
            "Cell \u001b[1;32mIn[66], line 25\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(data, params, cat_columns, num_columns)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(cross_val_score(xgb, X, y, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean())\n\u001b[0;32m     24\u001b[0m xgb\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 25\u001b[0m predict \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mpredict(data)\n\u001b[0;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m predict\n",
            "File \u001b[1;32mc:\\Users\\gosha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1525\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m   1516\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1517\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     iteration_range: Optional[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1523\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m   1524\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[1;32m-> 1525\u001b[0m         class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   1526\u001b[0m             X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1527\u001b[0m             output_margin\u001b[39m=\u001b[39;49moutput_margin,\n\u001b[0;32m   1528\u001b[0m             ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[0;32m   1529\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1530\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1531\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m         \u001b[39mif\u001b[39;00m output_margin:\n\u001b[0;32m   1534\u001b[0m             \u001b[39m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m             \u001b[39mreturn\u001b[39;00m class_probs\n",
            "File \u001b[1;32mc:\\Users\\gosha\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1114\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m   1115\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1116\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1117\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1119\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1120\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1121\u001b[0m         )\n\u001b[0;32m   1122\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1123\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gosha\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2269\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2265\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2266\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2267\u001b[0m         )\n\u001b[0;32m   2268\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 2269\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2271\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2272\u001b[0m         )\n\u001b[0;32m   2274\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m   2275\u001b[0m     _array_interface,\n\u001b[0;32m   2276\u001b[0m     _is_cudf_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2279\u001b[0m     _transform_pandas_df,\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m enable_categorical \u001b[39m=\u001b[39m _has_categorical(\u001b[39mself\u001b[39m, data)\n",
            "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 59, got 13"
          ]
        }
      ],
      "source": [
        "def pipeline(data, params, cat_columns, num_columns):\n",
        "\n",
        "    set_age(data)\n",
        "    set_cabine(data)\n",
        "    set_title(data)\n",
        "    set_fem_size(data)\n",
        "    data = set_fr_tic(data)\n",
        "\n",
        "    encode(data, cat_columns, num_columns)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    data[num_columns] = scaler.fit_transform(data[num_columns])\n",
        "\n",
        "    data = data.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\n",
        "\n",
        "    smote(X, y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=y)\n",
        "\n",
        "    xgb = XGBClassifier(**params)\n",
        "\n",
        "    print(cross_val_score(xgb, X, y, scoring = 'accuracy', cv=5, n_jobs=-1).mean())\n",
        "\n",
        "    xgb.fit(X_train, y_train)\n",
        "    predict = xgb.predict(data)\n",
        "\n",
        "    return predict\n",
        "\n",
        "predict = pipeline(test, params, cat_columns, num_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNTc0gQJstSw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
